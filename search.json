[{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"GNU General Public License","title":"GNU General Public License","text":"Version 3, 29 June 2007Copyright © 2007 Free Software Foundation, Inc. <http://fsf.org/> Everyone permitted copy distribute verbatim copies license document, changing allowed.","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/LICENSE.html","id":"preamble","dir":"","previous_headings":"","what":"Preamble","title":"GNU General Public License","text":"GNU General Public License free, copyleft license software kinds works. licenses software practical works designed take away freedom share change works. contrast, GNU General Public License intended guarantee freedom share change versions program–make sure remains free software users. , Free Software Foundation, use GNU General Public License software; applies also work released way authors. can apply programs, . speak free software, referring freedom, price. General Public Licenses designed make sure freedom distribute copies free software (charge wish), receive source code can get want , can change software use pieces new free programs, know can things. protect rights, need prevent others denying rights asking surrender rights. Therefore, certain responsibilities distribute copies software, modify : responsibilities respect freedom others. example, distribute copies program, whether gratis fee, must pass recipients freedoms received. must make sure , , receive can get source code. must show terms know rights. Developers use GNU GPL protect rights two steps: (1) assert copyright software, (2) offer License giving legal permission copy, distribute /modify . developers’ authors’ protection, GPL clearly explains warranty free software. users’ authors’ sake, GPL requires modified versions marked changed, problems attributed erroneously authors previous versions. devices designed deny users access install run modified versions software inside , although manufacturer can . fundamentally incompatible aim protecting users’ freedom change software. systematic pattern abuse occurs area products individuals use, precisely unacceptable. Therefore, designed version GPL prohibit practice products. problems arise substantially domains, stand ready extend provision domains future versions GPL, needed protect freedom users. Finally, every program threatened constantly software patents. States allow patents restrict development use software general-purpose computers, , wish avoid special danger patents applied free program make effectively proprietary. prevent , GPL assures patents used render program non-free. precise terms conditions copying, distribution modification follow.","code":""},{"path":[]},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/LICENSE.html","id":"id_0-definitions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"0. Definitions","title":"GNU General Public License","text":"“License” refers version 3 GNU General Public License. “Copyright” also means copyright-like laws apply kinds works, semiconductor masks. “Program” refers copyrightable work licensed License. licensee addressed “”. “Licensees” “recipients” may individuals organizations. “modify” work means copy adapt part work fashion requiring copyright permission, making exact copy. resulting work called “modified version” earlier work work “based ” earlier work. “covered work” means either unmodified Program work based Program. “propagate” work means anything , without permission, make directly secondarily liable infringement applicable copyright law, except executing computer modifying private copy. Propagation includes copying, distribution (without modification), making available public, countries activities well. “convey” work means kind propagation enables parties make receive copies. Mere interaction user computer network, transfer copy, conveying. interactive user interface displays “Appropriate Legal Notices” extent includes convenient prominently visible feature (1) displays appropriate copyright notice, (2) tells user warranty work (except extent warranties provided), licensees may convey work License, view copy License. interface presents list user commands options, menu, prominent item list meets criterion.","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/LICENSE.html","id":"id_1-source-code","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"1. Source Code","title":"GNU General Public License","text":"“source code” work means preferred form work making modifications . “Object code” means non-source form work. “Standard Interface” means interface either official standard defined recognized standards body, , case interfaces specified particular programming language, one widely used among developers working language. “System Libraries” executable work include anything, work whole, () included normal form packaging Major Component, part Major Component, (b) serves enable use work Major Component, implement Standard Interface implementation available public source code form. “Major Component”, context, means major essential component (kernel, window system, ) specific operating system () executable work runs, compiler used produce work, object code interpreter used run . “Corresponding Source” work object code form means source code needed generate, install, (executable work) run object code modify work, including scripts control activities. However, include work’s System Libraries, general-purpose tools generally available free programs used unmodified performing activities part work. example, Corresponding Source includes interface definition files associated source files work, source code shared libraries dynamically linked subprograms work specifically designed require, intimate data communication control flow subprograms parts work. Corresponding Source need include anything users can regenerate automatically parts Corresponding Source. Corresponding Source work source code form work.","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/LICENSE.html","id":"id_2-basic-permissions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"2. Basic Permissions","title":"GNU General Public License","text":"rights granted License granted term copyright Program, irrevocable provided stated conditions met. License explicitly affirms unlimited permission run unmodified Program. output running covered work covered License output, given content, constitutes covered work. License acknowledges rights fair use equivalent, provided copyright law. may make, run propagate covered works convey, without conditions long license otherwise remains force. may convey covered works others sole purpose make modifications exclusively , provide facilities running works, provided comply terms License conveying material control copyright. thus making running covered works must exclusively behalf, direction control, terms prohibit making copies copyrighted material outside relationship . Conveying circumstances permitted solely conditions stated . Sublicensing allowed; section 10 makes unnecessary.","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/LICENSE.html","id":"id_3-protecting-users-legal-rights-from-anti-circumvention-law","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"3. Protecting Users’ Legal Rights From Anti-Circumvention Law","title":"GNU General Public License","text":"covered work shall deemed part effective technological measure applicable law fulfilling obligations article 11 WIPO copyright treaty adopted 20 December 1996, similar laws prohibiting restricting circumvention measures. convey covered work, waive legal power forbid circumvention technological measures extent circumvention effected exercising rights License respect covered work, disclaim intention limit operation modification work means enforcing, work’s users, third parties’ legal rights forbid circumvention technological measures.","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/LICENSE.html","id":"id_4-conveying-verbatim-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"4. Conveying Verbatim Copies","title":"GNU General Public License","text":"may convey verbatim copies Program’s source code receive , medium, provided conspicuously appropriately publish copy appropriate copyright notice; keep intact notices stating License non-permissive terms added accord section 7 apply code; keep intact notices absence warranty; give recipients copy License along Program. may charge price price copy convey, may offer support warranty protection fee.","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/LICENSE.html","id":"id_5-conveying-modified-source-versions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"5. Conveying Modified Source Versions","title":"GNU General Public License","text":"may convey work based Program, modifications produce Program, form source code terms section 4, provided also meet conditions: ) work must carry prominent notices stating modified , giving relevant date. b) work must carry prominent notices stating released License conditions added section 7. requirement modifies requirement section 4 “keep intact notices”. c) must license entire work, whole, License anyone comes possession copy. License therefore apply, along applicable section 7 additional terms, whole work, parts, regardless packaged. License gives permission license work way, invalidate permission separately received . d) work interactive user interfaces, must display Appropriate Legal Notices; however, Program interactive interfaces display Appropriate Legal Notices, work need make . compilation covered work separate independent works, nature extensions covered work, combined form larger program, volume storage distribution medium, called “aggregate” compilation resulting copyright used limit access legal rights compilation’s users beyond individual works permit. Inclusion covered work aggregate cause License apply parts aggregate.","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/LICENSE.html","id":"id_6-conveying-non-source-forms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"6. Conveying Non-Source Forms","title":"GNU General Public License","text":"may convey covered work object code form terms sections 4 5, provided also convey machine-readable Corresponding Source terms License, one ways: ) Convey object code , embodied , physical product (including physical distribution medium), accompanied Corresponding Source fixed durable physical medium customarily used software interchange. b) Convey object code , embodied , physical product (including physical distribution medium), accompanied written offer, valid least three years valid long offer spare parts customer support product model, give anyone possesses object code either (1) copy Corresponding Source software product covered License, durable physical medium customarily used software interchange, price reasonable cost physically performing conveying source, (2) access copy Corresponding Source network server charge. c) Convey individual copies object code copy written offer provide Corresponding Source. alternative allowed occasionally noncommercially, received object code offer, accord subsection 6b. d) Convey object code offering access designated place (gratis charge), offer equivalent access Corresponding Source way place charge. need require recipients copy Corresponding Source along object code. place copy object code network server, Corresponding Source may different server (operated third party) supports equivalent copying facilities, provided maintain clear directions next object code saying find Corresponding Source. Regardless server hosts Corresponding Source, remain obligated ensure available long needed satisfy requirements. e) Convey object code using peer--peer transmission, provided inform peers object code Corresponding Source work offered general public charge subsection 6d. separable portion object code, whose source code excluded Corresponding Source System Library, need included conveying object code work. “User Product” either (1) “consumer product”, means tangible personal property normally used personal, family, household purposes, (2) anything designed sold incorporation dwelling. determining whether product consumer product, doubtful cases shall resolved favor coverage. particular product received particular user, “normally used” refers typical common use class product, regardless status particular user way particular user actually uses, expects expected use, product. product consumer product regardless whether product substantial commercial, industrial non-consumer uses, unless uses represent significant mode use product. “Installation Information” User Product means methods, procedures, authorization keys, information required install execute modified versions covered work User Product modified version Corresponding Source. information must suffice ensure continued functioning modified object code case prevented interfered solely modification made. convey object code work section , , specifically use , User Product, conveying occurs part transaction right possession use User Product transferred recipient perpetuity fixed term (regardless transaction characterized), Corresponding Source conveyed section must accompanied Installation Information. requirement apply neither third party retains ability install modified object code User Product (example, work installed ROM). requirement provide Installation Information include requirement continue provide support service, warranty, updates work modified installed recipient, User Product modified installed. Access network may denied modification materially adversely affects operation network violates rules protocols communication across network. Corresponding Source conveyed, Installation Information provided, accord section must format publicly documented (implementation available public source code form), must require special password key unpacking, reading copying.","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/LICENSE.html","id":"id_7-additional-terms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"7. Additional Terms","title":"GNU General Public License","text":"“Additional permissions” terms supplement terms License making exceptions one conditions. Additional permissions applicable entire Program shall treated though included License, extent valid applicable law. additional permissions apply part Program, part may used separately permissions, entire Program remains governed License without regard additional permissions. convey copy covered work, may option remove additional permissions copy, part . (Additional permissions may written require removal certain cases modify work.) may place additional permissions material, added covered work, can give appropriate copyright permission. Notwithstanding provision License, material add covered work, may (authorized copyright holders material) supplement terms License terms: ) Disclaiming warranty limiting liability differently terms sections 15 16 License; b) Requiring preservation specified reasonable legal notices author attributions material Appropriate Legal Notices displayed works containing ; c) Prohibiting misrepresentation origin material, requiring modified versions material marked reasonable ways different original version; d) Limiting use publicity purposes names licensors authors material; e) Declining grant rights trademark law use trade names, trademarks, service marks; f) Requiring indemnification licensors authors material anyone conveys material (modified versions ) contractual assumptions liability recipient, liability contractual assumptions directly impose licensors authors. non-permissive additional terms considered “restrictions” within meaning section 10. Program received , part , contains notice stating governed License along term restriction, may remove term. license document contains restriction permits relicensing conveying License, may add covered work material governed terms license document, provided restriction survive relicensing conveying. add terms covered work accord section, must place, relevant source files, statement additional terms apply files, notice indicating find applicable terms. Additional terms, permissive non-permissive, may stated form separately written license, stated exceptions; requirements apply either way.","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/LICENSE.html","id":"id_8-termination","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"8. Termination","title":"GNU General Public License","text":"may propagate modify covered work except expressly provided License. attempt otherwise propagate modify void, automatically terminate rights License (including patent licenses granted third paragraph section 11). However, cease violation License, license particular copyright holder reinstated () provisionally, unless copyright holder explicitly finally terminates license, (b) permanently, copyright holder fails notify violation reasonable means prior 60 days cessation. Moreover, license particular copyright holder reinstated permanently copyright holder notifies violation reasonable means, first time received notice violation License (work) copyright holder, cure violation prior 30 days receipt notice. Termination rights section terminate licenses parties received copies rights License. rights terminated permanently reinstated, qualify receive new licenses material section 10.","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/LICENSE.html","id":"id_9-acceptance-not-required-for-having-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"9. Acceptance Not Required for Having Copies","title":"GNU General Public License","text":"required accept License order receive run copy Program. Ancillary propagation covered work occurring solely consequence using peer--peer transmission receive copy likewise require acceptance. However, nothing License grants permission propagate modify covered work. actions infringe copyright accept License. Therefore, modifying propagating covered work, indicate acceptance License .","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/LICENSE.html","id":"id_10-automatic-licensing-of-downstream-recipients","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"10. Automatic Licensing of Downstream Recipients","title":"GNU General Public License","text":"time convey covered work, recipient automatically receives license original licensors, run, modify propagate work, subject License. responsible enforcing compliance third parties License. “entity transaction” transaction transferring control organization, substantially assets one, subdividing organization, merging organizations. propagation covered work results entity transaction, party transaction receives copy work also receives whatever licenses work party’s predecessor interest give previous paragraph, plus right possession Corresponding Source work predecessor interest, predecessor can get reasonable efforts. may impose restrictions exercise rights granted affirmed License. example, may impose license fee, royalty, charge exercise rights granted License, may initiate litigation (including cross-claim counterclaim lawsuit) alleging patent claim infringed making, using, selling, offering sale, importing Program portion .","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/LICENSE.html","id":"id_11-patents","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"11. Patents","title":"GNU General Public License","text":"“contributor” copyright holder authorizes use License Program work Program based. work thus licensed called contributor’s “contributor version”. contributor’s “essential patent claims” patent claims owned controlled contributor, whether already acquired hereafter acquired, infringed manner, permitted License, making, using, selling contributor version, include claims infringed consequence modification contributor version. purposes definition, “control” includes right grant patent sublicenses manner consistent requirements License. contributor grants non-exclusive, worldwide, royalty-free patent license contributor’s essential patent claims, make, use, sell, offer sale, import otherwise run, modify propagate contents contributor version. following three paragraphs, “patent license” express agreement commitment, however denominated, enforce patent (express permission practice patent covenant sue patent infringement). “grant” patent license party means make agreement commitment enforce patent party. convey covered work, knowingly relying patent license, Corresponding Source work available anyone copy, free charge terms License, publicly available network server readily accessible means, must either (1) cause Corresponding Source available, (2) arrange deprive benefit patent license particular work, (3) arrange, manner consistent requirements License, extend patent license downstream recipients. “Knowingly relying” means actual knowledge , patent license, conveying covered work country, recipient’s use covered work country, infringe one identifiable patents country reason believe valid. , pursuant connection single transaction arrangement, convey, propagate procuring conveyance , covered work, grant patent license parties receiving covered work authorizing use, propagate, modify convey specific copy covered work, patent license grant automatically extended recipients covered work works based . patent license “discriminatory” include within scope coverage, prohibits exercise , conditioned non-exercise one rights specifically granted License. may convey covered work party arrangement third party business distributing software, make payment third party based extent activity conveying work, third party grants, parties receive covered work , discriminatory patent license () connection copies covered work conveyed (copies made copies), (b) primarily connection specific products compilations contain covered work, unless entered arrangement, patent license granted, prior 28 March 2007. Nothing License shall construed excluding limiting implied license defenses infringement may otherwise available applicable patent law.","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/LICENSE.html","id":"id_12-no-surrender-of-others-freedom","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"12. No Surrender of Others’ Freedom","title":"GNU General Public License","text":"conditions imposed (whether court order, agreement otherwise) contradict conditions License, excuse conditions License. convey covered work satisfy simultaneously obligations License pertinent obligations, consequence may convey . example, agree terms obligate collect royalty conveying convey Program, way satisfy terms License refrain entirely conveying Program.","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/LICENSE.html","id":"id_13-use-with-the-gnu-affero-general-public-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"13. Use with the GNU Affero General Public License","title":"GNU General Public License","text":"Notwithstanding provision License, permission link combine covered work work licensed version 3 GNU Affero General Public License single combined work, convey resulting work. terms License continue apply part covered work, special requirements GNU Affero General Public License, section 13, concerning interaction network apply combination .","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/LICENSE.html","id":"id_14-revised-versions-of-this-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"14. Revised Versions of this License","title":"GNU General Public License","text":"Free Software Foundation may publish revised /new versions GNU General Public License time time. new versions similar spirit present version, may differ detail address new problems concerns. version given distinguishing version number. Program specifies certain numbered version GNU General Public License “later version” applies , option following terms conditions either numbered version later version published Free Software Foundation. Program specify version number GNU General Public License, may choose version ever published Free Software Foundation. Program specifies proxy can decide future versions GNU General Public License can used, proxy’s public statement acceptance version permanently authorizes choose version Program. Later license versions may give additional different permissions. However, additional obligations imposed author copyright holder result choosing follow later version.","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/LICENSE.html","id":"id_15-disclaimer-of-warranty","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"15. Disclaimer of Warranty","title":"GNU General Public License","text":"WARRANTY PROGRAM, EXTENT PERMITTED APPLICABLE LAW. EXCEPT OTHERWISE STATED WRITING COPYRIGHT HOLDERS /PARTIES PROVIDE PROGRAM “” WITHOUT WARRANTY KIND, EITHER EXPRESSED IMPLIED, INCLUDING, LIMITED , IMPLIED WARRANTIES MERCHANTABILITY FITNESS PARTICULAR PURPOSE. ENTIRE RISK QUALITY PERFORMANCE PROGRAM . PROGRAM PROVE DEFECTIVE, ASSUME COST NECESSARY SERVICING, REPAIR CORRECTION.","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/LICENSE.html","id":"id_16-limitation-of-liability","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"16. Limitation of Liability","title":"GNU General Public License","text":"EVENT UNLESS REQUIRED APPLICABLE LAW AGREED WRITING COPYRIGHT HOLDER, PARTY MODIFIES /CONVEYS PROGRAM PERMITTED , LIABLE DAMAGES, INCLUDING GENERAL, SPECIAL, INCIDENTAL CONSEQUENTIAL DAMAGES ARISING USE INABILITY USE PROGRAM (INCLUDING LIMITED LOSS DATA DATA RENDERED INACCURATE LOSSES SUSTAINED THIRD PARTIES FAILURE PROGRAM OPERATE PROGRAMS), EVEN HOLDER PARTY ADVISED POSSIBILITY DAMAGES.","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/LICENSE.html","id":"id_17-interpretation-of-sections-15-and-16","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"17. Interpretation of Sections 15 and 16","title":"GNU General Public License","text":"disclaimer warranty limitation liability provided given local legal effect according terms, reviewing courts shall apply local law closely approximates absolute waiver civil liability connection Program, unless warranty assumption liability accompanies copy Program return fee. END TERMS CONDITIONS","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/LICENSE.html","id":"how-to-apply-these-terms-to-your-new-programs","dir":"","previous_headings":"","what":"How to Apply These Terms to Your New Programs","title":"GNU General Public License","text":"develop new program, want greatest possible use public, best way achieve make free software everyone can redistribute change terms. , attach following notices program. safest attach start source file effectively state exclusion warranty; file least “copyright” line pointer full notice found. Also add information contact electronic paper mail. program terminal interaction, make output short notice like starts interactive mode: hypothetical commands show w show c show appropriate parts General Public License. course, program’s commands might different; GUI interface, use “box”. also get employer (work programmer) school, , sign “copyright disclaimer” program, necessary. information , apply follow GNU GPL, see <http://www.gnu.org/licenses/>. GNU General Public License permit incorporating program proprietary programs. program subroutine library, may consider useful permit linking proprietary applications library. want , use GNU Lesser General Public License instead License. first, please read <http://www.gnu.org/philosophy/--lgpl.html>.","code":"<one line to give the program's name and a brief idea of what it does.> Copyright (C) <year>  <name of author>  This program is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.  This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more details.  You should have received a copy of the GNU General Public License along with this program.  If not, see <http://www.gnu.org/licenses/>. <program>  Copyright (C) <year>  <name of author> This program comes with ABSOLUTELY NO WARRANTY; for details type 'show w'. This is free software, and you are welcome to redistribute it under certain conditions; type 'show c' for details."},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/articles/analysis_report.html","id":"vviq-group-analysis","dir":"Articles","previous_headings":"","what":"VVIQ group analysis","title":"Comprehensive data analysis report","text":"first analysed data light VVIQ groups, examining differences individuals aphantasia controls.","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/articles/analysis_report.html","id":"demographic-variables","dir":"Articles","previous_headings":"VVIQ group analysis","what":"Demographic variables","title":"Comprehensive data analysis report","text":"tested education level, fields study occupations participants association two groups. get_association_models() function designed compute Bayes Factors associations grouping variable (group) variables education, field occupation data. computation relies BayesFactor package. associated function format_association_table() extracts contingency table nested output get_association_models() formats clean table.","code":"df_association <- get_association_models(study_data, group)  df_association |> dplyr::select(Variable, log_bf10) #> # A tibble: 3 × 2 #> # Rowwise:  Variable #>   Variable   log_bf10 #>   <chr>         <dbl> #> 1 Education     -4.88 #> 2 Field         -5.41 #> 3 Occupation    -4.37  format_association_table(df_association, \"Education\") #> # A tibble: 6 × 3 #>   Education       Control Aphantasic #>   <fct>             <int>      <int> #> 1 Other                 5          4 #> 2 Upper secondary       1          0 #> 3 Post-secondary        9          5 #> 4 Bachelor             17         17 #> 5 Master               17         16 #> 6 Doctorate             2          3  format_association_table(df_association, \"Field\") #> # A tibble: 11 × 3 #>    Field                                        Control Aphantasic #>    <fct>                                          <int>      <int> #>  1 Generic programmes                                 4          4 #>  2 Education                                          1          1 #>  3 Arts, humanities                                   9         12 #>  4 Social sciences, journalism, information          11          4 #>  5 Business, Administration, Law                     10          8 #>  6 Natural sciences, mathematics, statistics          6          4 #>  7 Information, communication technologies            4          4 #>  8 Engineering, manufacturing, construction           3          3 #>  9 Agriculture, forestry, fisheries, veterinary       1          1 #> 10 Health and Welfare                                 2          3 #> 11 Services                                           0          1  format_association_table(df_association, \"Occupation\") #> # A tibble: 9 × 3 #>   Occupation                  Control Aphantasic #>   <fct>                         <int>      <int> #> 1 No answer                         1          1 #> 2 Unemployed                        1          1 #> 3 Student                          20         12 #> 4 Science and Engineering           2          4 #> 5 Health                            2          6 #> 6 Teaching                          4          3 #> 7 Business, Administration          9         10 #> 8 Information, Communications       8          6 #> 9 Social, Cultural, Legal           4          2"},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/articles/analysis_report.html","id":"main-score-variables","dir":"Articles","previous_headings":"VVIQ group analysis","what":"Main score variables","title":"Comprehensive data analysis report","text":"analysed main questionnaire task score variables data, : VVIQ, three OSIVQ subscales (object, spatial, verbal), seven Psi-Q subscales (vision, auditory, smell, taste, touch, sensations, feelings), Raven matrices, SRI (spatial test), digit span, spatial span, similarities test, WCST (executive functions test), reading comprehension task. fitted Bayesian linear models various variables model participant groups categorical predictors age continuous covariate control potential influence latter. used bayestestR package compute Bayes Factor inclusion grouping variable age covariate models. get Bayes Factors contrasts groups, fitted models prior posterior distributions using rstanarm package (default settings) used emmeans package compute contrasts. get_mean_sd() function provides quick way compute format mean standard deviation variables group, get_bf_inclusion() get_contrast_bf() functions take care two modelling steps described . three wrapped get_full_model_table() function, designed run full analysis pipeline variable long format data frame appropriate columns. get_longer() function designed perform transformation wide long format easily, returning clean column names values. code fit everything straightforward: number models fit quite large, code run . However, results saved natively package models_list object. resulting data frame two groups first item list: filter_study_variables() function convenience function filter set variables study. table contains original raw scores, leaving transformed variables created later analyses. Two functions provided visualise data, plot_score_violins() (used paper groups) plot_score_radars() (used later paper clusters). latter requires Cluster column (know, great design), ’ll use later. plot_score_violins() uses see package plot half-violins, plot_score_radars() uses superb package plot radar charts. scale_vars() function used rescale variables 0 1 plot easily scale.","code":"study_data |>    get_longer() |>    dplyr::select(id, Group, Variable, value) |>    head() #> # A tibble: 6 × 4 #>   id    Group   Variable       value #>   <chr> <fct>   <fct>          <dbl> #> 1 7210  Control VVIQ           65    #> 2 7210  Control OSIVQ-Object   45    #> 3 7210  Control OSIVQ-Spatial  45    #> 4 7210  Control OSIVQ-Verbal   54    #> 5 7210  Control Psi-Q Vision    8    #> 6 7210  Control Psi-Q Audition  7.67 study_data |> get_longer() |> get_full_model_table(Group) models_list$group_models |>    filter_study_variables(\"original\") |>    dplyr::select(!Comparison) |>    knitr::kable() study_data |>    scale_vars() |>    get_longer() |>   filter_study_variables(\"original\") |>    plot_score_violins()"},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/articles/analysis_report.html","id":"cluster-analysis","dir":"Articles","previous_headings":"","what":"Cluster analysis","title":"Comprehensive data analysis report","text":"Faced lack explanatory power VVIQ groups many variables, set explore structure data using clustering analysis. first required study relationships variables select relevant describe sample.","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/articles/analysis_report.html","id":"correlations","dir":"Articles","previous_headings":"Cluster analysis","what":"Correlations","title":"Comprehensive data analysis report","text":"used partial correlations identify strongest links variables variable reduction reducing bias potential spurious correlations. correlate_vars() function wraps function correlation package compute correlations conveniently renames variables resulting object. Two plotting functions provided visualise results, plot_score_cor_matrix() plot_score_cor_graph(). two wrapped plot_score_cor_joint() produce joint plot correlation matrix graph visualisation correlations specific overlapped layout using patchwork package.  represented coloured nodes, partial correlations allowed identify related variables relevant merge keep clustering analysis. clustering process conducted seven following variables: Visual imagery (VVIQ + OSIVQ-O + Psi-Q V), Sensory imagery (Psi-Q Sm+Ta++Se+Fe), Spatial imagery (OSIVQ-S + SRI), Verbal strategies (OSIVQ-V), Raven + Digit span, Verbal reasoning (Similarity) Spatial span.","code":"study_data |> correlate_vars(partial = TRUE) |> plot_score_cor_joint()"},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/articles/analysis_report.html","id":"number-of-clusters","dir":"Articles","previous_headings":"Cluster analysis","what":"Number of clusters","title":"Comprehensive data analysis report","text":"chose use model-based method clustering (Gaussian Mixture Modelling) mclust package. cluster_selected_vars() function computes clustering variables described . Internally, calls scale_reduce_vars() function, creates reduced composite variables identified partial correlations rescales 0 1. optimal model number clusters determined using Bayesian Information Criterion (BIC) implemented mclust package. plot_clusters_bic uses factoextra represent results model comparison visually.","code":"study_data |> cluster_selected_vars() |> plot_clusters_bic()"},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/articles/analysis_report.html","id":"clustering-results","dir":"Articles","previous_headings":"Cluster analysis","what":"Clustering results","title":"Comprehensive data analysis report","text":"merge_clusters() function allows merge original data, reduced variables cluster results easily. two clusters containing aphantasic (cluster ) control (cluster C) participants, another cluster (cluster B) mixed. dividing latter two “sub-clusters”, created new subcluster variable analyse. radar charts convenient way visualise scores clusters sub-clusters reduced variables:  computed Bayes Factors association clusters subclusters demographic variables: Just like group models, code model score variables clusters sub-clusters straightforward: … likewise, takes run, models pre-computed results stored models_list object. Bayes Factors inclusion predictors models variable, clusters subclusters: Finally, can get pairwise comparisons clusters subclusters, Bayes Factors contrasts: …concludes data analysis report.","code":"df_merged <- merge_clusters(   df_raw     = study_data,   df_red     = scale_reduce_vars(study_data),   clustering = cluster_selected_vars(study_data) ) colnames(df_merged) #>  [1] \"id\"                  \"group\"               \"cluster\"             #>  [4] \"subcluster\"          \"age\"                 \"sex\"                 #>  [7] \"education\"           \"field\"               \"field_code\"          #> [10] \"occupation\"          \"occupation_code\"     \"vviq\"                #> [13] \"osivq_o\"             \"osivq_s\"             \"osivq_v\"             #> [16] \"psiq_vis\"            \"psiq_aud\"            \"psiq_od\"             #> [19] \"psiq_gout\"           \"psiq_tou\"            \"psiq_sens\"           #> [22] \"psiq_feel\"           \"score_raven\"         \"score_sri\"           #> [25] \"span_spatial\"        \"span_digit\"          \"wcst_accuracy\"       #> [28] \"score_similarities\"  \"score_comprehension\" \"visual_imagery\"      #> [31] \"auditory_imagery\"    \"sensory_imagery\"     \"spatial_imagery\"     #> [34] \"verbal_strategies\"   \"fluid_intelligence\"  \"verbal_reasoning\"    #> [37] \"spatial_span\"  df_merged |>    dplyr::reframe(     .by = c(group, cluster),     n       = dplyr::n(),     vviq    = mean(vviq),     object  = mean(osivq_o),     spatial = mean(osivq_s),     verbal  = mean(osivq_v)   ) |>    dplyr::arrange(cluster) #> # A tibble: 4 × 7 #>   group      cluster         n  vviq object spatial verbal #>   <fct>      <fct>       <int> <dbl>  <dbl>   <dbl>  <dbl> #> 1 Aphantasic A (Aphant.)    32  18.1   23.9    37.6   52.8 #> 2 Control    B (Mixed)      17  49.9   48.8    50.7   41.6 #> 3 Aphantasic B (Mixed)      13  19     26.4    43.3   41.1 #> 4 Control    C (Control)    34  62.2   56.7    40.0   44 # Attaching superb is necessary to avoid bugs with the 1.0 library(superb)  df_merged_long_reduced <-    df_merged |>    scale_vars() |>    get_longer() |>    filter_study_variables(\"reduced\")  plot_score_radars(df_merged_long_reduced, Cluster, r_off = 6, l_off = 6) +    plot_score_radars(df_merged_long_reduced, Subcluster, r_off = 6, l_off = 6) df_asso_clusters <- get_association_models(df_merged, cluster) df_asso_subclusters <- get_association_models(df_merged, subcluster)  df_asso_clusters |> dplyr::select(Variable, log_bf10) #> # A tibble: 3 × 2 #> # Rowwise:  Variable #>   Variable   log_bf10 #>   <chr>         <dbl> #> 1 Education     -7.44 #> 2 Field         -6.06 #> 3 Occupation    -3.88 df_asso_subclusters |> dplyr::select(Variable, log_bf10) #> # A tibble: 3 × 2 #> # Rowwise:  Variable #>   Variable   log_bf10 #>   <chr>         <dbl> #> 1 Education     -9.84 #> 2 Field         -7.7  #> 3 Occupation    -7.06  df_asso_clusters |> format_association_table(\"Education\") #> # A tibble: 6 × 4 #>   Education       `A (Aphant.)` `B (Mixed)` `C (Control)` #>   <fct>                   <int>       <int>         <int> #> 1 Other                       3           2             4 #> 2 Post-secondary              3           5             6 #> 3 Bachelor                   10          12            12 #> 4 Master                     13          10            10 #> 5 Doctorate                   3           0             2 #> 6 Upper secondary             0           1             0 df_asso_clusters |> format_association_table(\"Field\") #> # A tibble: 11 × 4 #>    Field                                 `A (Aphant.)` `B (Mixed)` `C (Control)` #>    <fct>                                         <int>       <int>         <int> #>  1 Generic programmes                                2           5             1 #>  2 Education                                         1           0             1 #>  3 Arts, humanities                                  9           6             6 #>  4 Social sciences, journalism, informa…             4           2             9 #>  5 Business, Administration, Law                     6           4             8 #>  6 Natural sciences, mathematics, stati…             3           5             2 #>  7 Information, communication technolog…             2           3             3 #>  8 Engineering, manufacturing, construc…             1           3             2 #>  9 Agriculture, forestry, fisheries, ve…             1           0             1 #> 10 Health and Welfare                                3           1             1 #> 11 Services                                          0           1             0 df_asso_clusters |> format_association_table(\"Occupation\") #> # A tibble: 9 × 4 #>   Occupation                  `A (Aphant.)` `B (Mixed)` `C (Control)` #>   <fct>                               <int>       <int>         <int> #> 1 Unemployed                              1           0             1 #> 2 Student                                 9           9            14 #> 3 Science and Engineering                 3           1             2 #> 4 Health                                  6           0             2 #> 5 Teaching                                2           3             2 #> 6 Business, Administration                8           5             6 #> 7 Information, Communications             2           9             3 #> 8 Social, Cultural, Legal                 1           2             3 #> 9 No answer                               0           1             1  df_asso_subclusters |> format_association_table(\"Education\") #> # A tibble: 6 × 5 #>   Education       `A (Aphant.)` `B-Aphant.` `B-Control` `C (Control)` #>   <fct>                   <int>       <int>       <int>         <int> #> 1 Other                       3           1           1             4 #> 2 Post-secondary              3           2           3             6 #> 3 Bachelor                   10           7           5            12 #> 4 Master                     13           3           7            10 #> 5 Doctorate                   3           0           0             2 #> 6 Upper secondary             0           0           1             0 df_asso_subclusters |> format_association_table(\"Field\") #> # A tibble: 11 × 5 #>    Field                     `A (Aphant.)` `B-Aphant.` `B-Control` `C (Control)` #>    <fct>                             <int>       <int>       <int>         <int> #>  1 Generic programmes                    2           2           3             1 #>  2 Education                             1           0           0             1 #>  3 Arts, humanities                      9           3           3             6 #>  4 Social sciences, journal…             4           0           2             9 #>  5 Business, Administration…             6           2           2             8 #>  6 Natural sciences, mathem…             3           1           4             2 #>  7 Information, communicati…             2           2           1             3 #>  8 Engineering, manufacturi…             1           2           1             2 #>  9 Agriculture, forestry, f…             1           0           0             1 #> 10 Health and Welfare                    3           0           1             1 #> 11 Services                              0           1           0             0 df_asso_subclusters |> format_association_table(\"Occupation\") #> # A tibble: 9 × 5 #>   Occupation                 `A (Aphant.)` `B-Aphant.` `B-Control` `C (Control)` #>   <fct>                              <int>       <int>       <int>         <int> #> 1 Unemployed                             1           0           0             1 #> 2 Student                                9           3           6            14 #> 3 Science and Engineering                3           1           0             2 #> 4 Health                                 6           0           0             2 #> 5 Teaching                               2           1           2             2 #> 6 Business, Administration               8           2           3             6 #> 7 Information, Communicatio…             2           4           5             3 #> 8 Social, Cultural, Legal                1           1           1             3 #> 9 No answer                              0           1           0             1 df_merged_long <-    df_merged |>    scale_vars() |>    get_longer()  cluster_models    <- get_full_model_table(df_merged_long, Cluster) subcluster_models <- get_full_model_table(df_merged_long, Subcluster) models_list$cluster_models |>    dplyr::select(1:7) |>    dplyr::distinct() |>    knitr::kable() models_list$subcluster_models |>    dplyr::select(1:7) |>    dplyr::distinct() |>    knitr::kable() models_list$cluster_models |>    dplyr::select(1, 8:11) |>    knitr::kable() models_list$subcluster_models |>    dplyr::select(1, 8:11) |>    knitr::kable() sessioninfo::session_info() #> ─ Session info ─────────────────────────────────────────────────────────────── #>  setting  value #>  version  R version 4.5.2 (2025-10-31) #>  os       Ubuntu 24.04.3 LTS #>  system   x86_64, linux-gnu #>  ui       X11 #>  language en #>  collate  C.UTF-8 #>  ctype    C.UTF-8 #>  tz       UTC #>  date     2025-11-19 #>  pandoc   3.1.11 @ /opt/hostedtoolcache/pandoc/3.1.11/x64/ (via rmarkdown) #>  quarto   1.8.26 @ /usr/local/bin/quarto #>  #> ─ Packages ─────────────────────────────────────────────────────────────────── #>  ! package                       * version    date (UTC) lib source #>    abind                           1.4-8      2024-09-12 [1] RSPM #>    aphantasiaCognitiveClustering * 1.0        2025-11-19 [1] local #>    backports                       1.5.0      2024-05-23 [1] RSPM #>    BayesFactor                     0.9.12-4.7 2024-01-24 [1] RSPM #>    bayestestR                      0.17.0     2025-08-29 [1] RSPM #>    BiocManager                     1.30.27    2025-11-14 [1] RSPM #>    broom                           1.0.10     2025-09-13 [1] RSPM #>    bslib                           0.9.0      2025-01-30 [1] RSPM #>    cachem                          1.1.0      2024-05-16 [1] RSPM #>    car                             3.1-3      2024-09-27 [1] RSPM #>    carData                         3.0-5      2022-01-06 [1] RSPM #>    cli                             3.6.5      2025-04-23 [1] RSPM #>    coda                            0.19-4.1   2024-01-31 [1] RSPM #>    correlation                     0.8.8      2025-07-08 [1] RSPM #>    crayon                          1.5.3      2024-06-20 [1] RSPM #>    datawizard                      1.3.0      2025-10-11 [1] RSPM #>    desc                            1.4.3      2023-12-10 [1] RSPM #>  P devtools                      * 2.4.6      2025-10-03 [?] RSPM #>    digest                          0.6.38     2025-11-12 [1] RSPM #>    dplyr                           1.1.4      2023-11-17 [1] RSPM #>  P ellipsis                        0.3.2      2021-04-29 [?] RSPM #>    evaluate                        1.0.5      2025-08-27 [1] RSPM #>    factoextra                      1.0.7      2020-04-01 [1] RSPM #>    farver                          2.1.2      2024-05-13 [1] RSPM #>    fastmap                         1.2.0      2024-05-15 [1] RSPM #>    forcats                         1.0.1      2025-09-25 [1] RSPM #>  P foreign                         0.8-90     2025-03-31 [?] CRAN (R 4.5.2) #>    Formula                         1.2-5      2023-02-24 [1] RSPM #>    fs                              1.6.6      2025-04-12 [1] RSPM #>    generics                        0.1.4      2025-05-09 [1] RSPM #>    ggforce                         0.5.0      2025-06-18 [1] RSPM #>    ggplot2                         4.0.1      2025-11-14 [1] RSPM #>    ggpubr                          0.6.2      2025-10-17 [1] RSPM #>    ggraph                          2.2.2      2025-08-24 [1] RSPM #>    ggrepel                         0.9.6      2024-09-07 [1] RSPM #>    ggsignif                        0.6.4      2022-10-13 [1] RSPM #>    glue                            1.8.0      2024-09-30 [1] RSPM #>    graphlayouts                    1.2.2      2025-01-23 [1] RSPM #>    gridExtra                       2.3        2017-09-09 [1] RSPM #>    gtable                          0.3.6      2024-10-25 [1] RSPM #>    htmltools                       0.5.8.1    2024-04-04 [1] RSPM #>    htmlwidgets                     1.6.4      2023-12-06 [1] RSPM #>    httpuv                          1.6.16     2025-04-16 [1] RSPM #>    igraph                          2.2.1      2025-10-27 [1] RSPM #>    insight                         1.4.2      2025-09-02 [1] RSPM #>    jquerylib                       0.1.4      2021-04-26 [1] RSPM #>    jsonlite                        2.0.0      2025-03-27 [1] RSPM #>    knitr                           1.50       2025-03-16 [1] RSPM #>    labeling                        0.4.3      2023-08-29 [1] RSPM #>    later                           1.4.4      2025-08-27 [1] RSPM #>  P lattice                         0.22-7     2025-04-02 [?] CRAN (R 4.5.2) #>    lifecycle                       1.0.4      2023-11-07 [1] RSPM #>    lsr                             0.5.2      2021-12-01 [1] RSPM #>    magrittr                        2.0.4      2025-09-12 [1] RSPM #>  P MASS                            7.3-65     2025-02-28 [?] CRAN (R 4.5.2) #>  P Matrix                          1.7-4      2025-08-28 [?] CRAN (R 4.5.2) #>    MatrixModels                    0.5-4      2025-03-26 [1] RSPM #>    mclust                          6.1.2      2025-10-31 [1] RSPM #>    memoise                         2.0.1      2021-11-26 [1] RSPM #>    mime                            0.13       2025-03-17 [1] RSPM #>    mvtnorm                         1.3-3      2025-01-10 [1] RSPM #>    otel                            0.2.0      2025-08-29 [1] RSPM #>    patchwork                       1.3.2      2025-08-25 [1] RSPM #>    pbapply                         1.7-4      2025-07-20 [1] RSPM #>    pillar                          1.11.1     2025-09-17 [1] RSPM #>    pkgbuild                        1.4.8      2025-05-26 [1] RSPM #>    pkgconfig                       2.0.3      2019-09-22 [1] RSPM #>    pkgdown                         2.2.0      2025-11-06 [1] any (@2.2.0) #>    pkgload                         1.4.1      2025-09-23 [1] RSPM #>    plyr                            1.8.9      2023-10-02 [1] RSPM #>    polyclip                        1.10-7     2024-07-23 [1] RSPM #>    promises                        1.5.0      2025-11-01 [1] RSPM #>    purrr                           1.2.0      2025-11-04 [1] RSPM #>    R6                              2.6.1      2025-02-15 [1] RSPM #>    ragg                            1.5.0      2025-09-02 [1] RSPM #>    rbibutils                       2.4        2025-11-07 [1] RSPM #>    RColorBrewer                    1.1-3      2022-04-03 [1] RSPM #>    Rcpp                            1.1.0      2025-07-02 [1] RSPM #>    Rdpack                          2.6.4      2025-04-09 [1] RSPM #>  P remotes                         2.5.0      2024-03-17 [?] RSPM #>    renv                            1.1.4      2025-03-20 [1] RSPM (R 4.5.0) #>    reshape2                        1.4.5      2025-11-12 [1] RSPM #>    rlang                           1.1.6      2025-04-11 [1] RSPM #>    rmarkdown                       2.30       2025-09-28 [1] RSPM #>    rrapply                         1.2.7      2024-06-26 [1] RSPM #>    rstatix                         0.7.3      2025-10-18 [1] RSPM #>    S7                              0.2.1      2025-11-14 [1] RSPM #>    sass                            0.4.10     2025-04-11 [1] RSPM #>    scales                          1.4.0      2025-04-24 [1] RSPM #>    see                             0.12.0     2025-09-14 [1] RSPM #>    sessioninfo                     1.2.3      2025-02-05 [1] RSPM #>    shiny                           1.11.1     2025-07-03 [1] RSPM #>    shinyBS                         0.61.1     2022-04-17 [1] RSPM #>    stringi                         1.8.7      2025-03-27 [1] RSPM #>    stringr                         1.6.0      2025-11-04 [1] RSPM #>    superb                        * 1.0.0      2025-08-18 [1] RSPM #>    systemfonts                     1.3.1      2025-10-01 [1] RSPM #>    textshaping                     1.0.4      2025-10-10 [1] RSPM #>    tibble                          3.3.0      2025-06-08 [1] RSPM #>    tidygraph                       1.3.1      2024-01-30 [1] RSPM #>    tidyr                           1.3.1      2024-01-24 [1] RSPM #>    tidyselect                      1.2.1      2024-03-11 [1] RSPM #>    tweenr                          2.0.3      2024-02-26 [1] RSPM #>  P usethis                       * 3.2.1      2025-09-06 [?] RSPM #>    utf8                            1.2.6      2025-06-08 [1] RSPM #>    vctrs                           0.6.5      2023-12-01 [1] RSPM #>    viridis                         0.6.5      2024-01-29 [1] RSPM #>    viridisLite                     0.4.2      2023-05-02 [1] RSPM #>    withr                           3.0.2      2024-10-28 [1] RSPM #>    xfun                            0.54       2025-10-30 [1] RSPM #>    xtable                          1.8-4      2019-04-21 [1] RSPM #>    yaml                            2.3.10     2024-07-26 [1] RSPM #>  #>  [1] /home/runner/.cache/R/renv/library/aphantasiaCognitiveClustering-3eb0a6a4/linux-ubuntu-noble/R-4.5/x86_64-pc-linux-gnu #>  [2] /home/runner/.cache/R/renv/sandbox/linux-ubuntu-noble/R-4.5/x86_64-pc-linux-gnu/8f3cef43 #>  #>  * ── Packages attached to the search path. #>  P ── Loaded and on-disk path mismatch. #>  #> ──────────────────────────────────────────────────────────────────────────────"},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/articles/manuscript.html","id":"unsupervised-clustering-reveals-spatial-and-verbal-cognitive-profiles-in-aphantasia-and-typical-imagery","dir":"Articles","previous_headings":"","what":"Unsupervised clustering reveals spatial and verbal cognitive profiles in aphantasia and typical imagery","title":"Reproducible manuscript","text":"Keywords: aphantasia, mental imagery, individual differences, cognitive profiles, reasoning, working memory, unsupervised clustering","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/articles/manuscript.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Reproducible manuscript","text":"Visual imagery, commonly referred “seeing mind’s eye”, designates pseudo-perceptual visual experience mental images absence corresponding external stimulus (Pearson, 2019). large individual differences visual imagery vividness (.e. intensity detail mental images) across spectrum going absence mental imagery, phenomenon recently named “aphantasia” (Zeman et al., 2015), extremely vivid perception-like imagery, named “hyperphantasia” (Zeman et al., 2020). introduction term “aphantasia” 2015 led wave research subject, exploring underlying causes consequences potential positive negative outcomes. large body research aphantasia mainly identified potential deficits associated . Specifically, condition associated reduction autobiographical memory (Dawes et al., 2020, 2022; Milton et al., 2021; Monzel, Leelaarporn, et al., 2023), lack atemporal future imagination (Milton et al., 2021), increased face recognition difficulties (Milton et al., 2021; Palermo et al., 2022; Zeman et al., 2020), reduced dreams (Dawes et al., 2020), decreased motor simulation (Dupont et al., 2024). focus deficits left potential positive aspects aphantasia largely unexplored, even though empirical evidence recent studies shown individuals aphantasia performed well “typical” visual imagery various types tasks presumed require ability, visual visuo-spatial working memory (Keogh et al., 2021; Pounder et al., 2022; Reeder et al., 2024). Research hinted advantages aphantasia focused mainly emotional processing. Individuals aphantasia shown less prone sensory sensitivity (Dance et al., 2021), less reactive reading frightening scenarios (Wicken et al., 2021), less sensible intrusive memories (Keogh et al., 2023) suggesting aphantasia help reduce sensory overwhelm, potentially protect emotional overreaction. Recently, Monzel et al. (2023) proposed aphantasia understood within framework “neurodivergence” state representing atypical functional cognitive processing, advantages disadvantages. specifics “alternative thinking” advantages, however, remain understood. Interestingly, Zeman et al. (2020) found individuals aphantasia seemed likely work STEM fields (Science, Technology, Engineering, Mathematics), whereas hyperphantasics, end spectrum, likely work art-related professions. Drawing patterns emerging large-scale exploratory survey, Zeman et al. (2020) proposed broad hypothesis , whereas hyperphantasia might characterized episodic sensorily-rich mode thinking, aphantasia might characterized semantic fact-oriented approach. visual/abstract polarity thinking styles reflected career preferences observed Zeman et al. (2020) reminiscent work Object-Spatial-Verbal model cognitive styles developed Blazhenkova & Kozhevnikov (2009) associated questionnaire (Object-Spatial Imagery Verbal Questionnaire, OSIVQ). Based behavioural neuroimaging studies healthy individuals (Kosslyn et al., 1995; Kozhevnikov et al., 2002; Wallace, 1990) neuropsychological studies brain-damaged patients (Bartolomeo, 2002; Farah et al., 1988), Blazhenkova et al. (2006) showed visual-object imagery (imagery colors, shapes, brightness, etc.) dissociated spatial imagery (imagery location, movement orientation). Blazhenkova & Kozhevnikov (2009) challenged prevailing Visualizer-Verbalizer model cognitive styles (Paivio & Ernest, 1971; Richardson, 1977) introduce spatial dimension major form imagery cognitive style right, alongside visual verbal styles. showed several widely used paradigms, Mental Rotation Task (Shepard & Metzler, 1971) Paper Folding Test (Ekstrom, 1976), often considered visual, associated visual imagery visual cognitive styles per se, spatial imagery spatial cognitive styles (Blazhenkova et al., 2006; Blazhenkova & Kozhevnikov, 2009; Kozhevnikov et al., 2010; Vannucci et al., 2006). Consistent observation Zeman et al. (2020) prevalence STEM occupations aphantasia artists hyperphantasia, several studies Object-Spatial-Verbal model shown visual-object cognitive styles particularly prevalent among visual artists, spatial styles -represented scientific fields verbal styles prevail literature humanities, among students professionals (Blazhenkova et al., 2006; Blazhenkova & Kozhevnikov, 2009, 2010; Kozhevnikov et al., 2005; Kozhevnikov et al., 2010). results corroborated various studies showing spatial imagery preserved enhanced aphantasia, subjective spatial scale Object-Spatial Imagery Questionnaire (OSIQ, first version OSIVQ without verbal scale, Blazhenkova et al., 2006) various spatial rotation, manipulation spatial working memory tasks (Bainbridge et al., 2021; Dawes et al., 2020; Keogh et al., 2021; Keogh & Pearson, 2018; Pounder et al., 2022; Reeder et al., 2024; Zeman et al., 2015). Several studies also revealed wide range spatial, sensorimotor/kinaesthetic, verbal amodal memory strategies reported individuals aphantasia (supposedly) visual tasks (Keogh et al., 2021; Reeder et al., 2024; Zeman et al., 2020). diversity modes thinking therefore distributed across several dimensions, including visual-object spatial representation, potentially extending verbal semantic domains. verbal (“propositional”) aspect representations cognitive strategies, although often mentioned potential candidate alternative strategies visual aphantasia, scarcely studied. Previous articles examined relevance cognitive style models understanding aphantasia focused object/spatial dissociation (Blazhenkova & Pechenkova, 2019; Palermo et al., 2022) visual/verbal dissociation (beranAssessingAphantasiaPrevalence2023?; takahashiDiversityAphantasiaRevealed2023?) none far considered three dimensions simultaneously. Object-Spatial-Verbal model cognitive styles allow study verbal representations coherent framework alongside visual spatial imagery shed light cognitive strategies individuals aphantasia. Therefore, objective present study two-fold: () explore cognitive profiles individuals aphantasia using Object-Spatial-Verbal model imagery cognitive styles theorised Blazhenkova & Kozhevnikov (2009), (b) explore whether profiles might related cognitive performance. hypothesised individuals aphantasia tend adopt spatial verbal cognitive profiles, profiles associated specific performance patterns. First, hypothesised profiles might related reasoning performance. Spatial imagery known involved play major role abstract reasoning (Wai et al., 2009). context, absence visual imagery aphantasia priority focus spatial representations aphantasia (Bainbridge et al., 2021; Keogh et al., 2021; Reeder et al., 2024) hypothesised facilitate abstract reasoning. Second, hypothesised spatial verbal cognitive profiles explain individual differences working memory performance, depending modality involved. Previous studies failed find differences working memory performance individuals aphantasia controls (e.g., Keogh et al., 2021; Pounder et al., 2022; Reeder et al., 2024), took account variations visual-object dimension imagery. Accounting use spatial verbal representations working memory provide insight processes strategies underlying performance individuals aphantasia various tasks (Pearson & Keogh, 2019). Third, put forward general hypothesis individuals aphantasia distinct verbal cognitive profiles, good reading comprehension skills. However, studies established positive correlation reading comprehension visual mental imagery (e.g., Suggate & Lenhard, 2022), suggesting central role latter. Although similar reading habits observed people aphantasia typical imagery (speedRoleVisualImagery2024?), studies yet conducted reading comprehension ecological context people aphantasia. research provide clearer picture advantages disadvantages aphantasia complex reading tasks involving verbal skills, working memory mental imagery. Finally, hypothesised performance individuals aphantasia tasks supposed require visual imagery might linked greater flexibility switching alternative strategies (e.g. propositional, motor, etc.). case, characterised particularly efficient executive functioning. Thus, present study also included task designed probe executive functions. sum, present study aimed gain better understanding cognitive profiles individuals aphantasia strategies representing processing information. sought identify patterns performance accomplishing various cognitive tasks individuals aphantasia controls relate subjective preferences visual, spatial verbal processing. end, online study designed, integrating questionnaires behavioural tasks assess visual imagery, spatial imagery, verbal strategies, spatial, verbal non-verbal reasoning, verbal visuo-spatial working memory, reading comprehension, executive functions. Based previous work showing differences cognitive performance individuals aphantasia controls memory tasks (Keogh et al., 2021; Knight et al., 2022; Pounder et al., 2022), expected dividing participants two groups according visual imagery ability fully explain substantial differences task performance. Thus, planned explore hypothesis hidden sub-groups within sample using data-driven unsupervised clustering method. analysis trans-categorical (including groups) included measures cognitive abilities assess similarities differences participants beyond visual imagery. trans-categorical, refer approach goes beyond predefined “diagnostic” categories examine individual variability across continuous multidimensional spaces. Instead assuming cognitive differences fully explained membership priori group defined single variable (aphantasic vs. typical imagery), approach considers profiles overlapping seeks latent structures emergent clusters cut across categories using multiple variables. example, characteristic strengths spatial verbal reasoning may appear individuals without aphantasia, suggesting traits restricted one group distributed along continua. framework particularly relevant cognitive psychology, constructs imagery, memory, reasoning interact vary one individual another, regardless predefined boundaries. proposed data analysis plan resulted clusters characterized visual, spatial, verbal cognitive styles, able explain task performance. light patterns, discuss potential Object-Spatial-Verbal model understanding cognitive processes strategies aphantasia.","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/articles/manuscript.html","id":"methods","dir":"Articles","previous_headings":"","what":"Methods","title":"Reproducible manuscript","text":"part study procedures analysis plan preregistered prior research undertaken. report data exclusions, inclusion/exclusion criteria, manipulations, measures study. Participants French speakers, normal corrected vision none participants reported known reading disorders. recruited online groups unrelated mental imagery (social networks, French cognitive science information network, etc.) groups dedicated aphantasia visual imagery. study link sent participants volunteered contacting team email. study carried following recommendations French Law (Loi Jardé n◦2012- 300), accordance ethical standards institutional research committee Declaration Helsinki later amendments. Informed consent obtained individual participants included study . Participation without compensation. study exploratory, sample size determined priori. data participants completed tasks included analyses. Participants skipped task extremely fast removed data. 1200 people opened link study, 96 completed tasks, making final sample. questionnaire statistics detailed results part . Vividness Visual Imagery Questionnaire (VVIQ, Marks, 1973) used assess visual imagery ability. VVIQ 16-item self-report scale asks participants imagine person several scenes rate vividness mental images using 5-point scale ranging 1 (“imagery , just know ’re thinking object”) 5 (“Perfectly clear vivid normal vision”). Scores range 16 80. total score 32, often used threshold define aphantasia (Dawes et al., 2020; Keogh et al., 2021; e.g., dancePrevalenceAphantasiaImagery2022?; speedRoleVisualImagery2024?), equivalent score 2 (“vague faint”) item questionnaire. internal reliability (Cronbach’s α\\alpha) VVIQ .88 (McKelvie, 1995). Object-Spatial Imagery Verbal Questionnaire (OSIVQ, Blazhenkova & Kozhevnikov, 2009) used evaluate imagery strategies cognitive styles. OSIVQ 45-item scale asks participants indicate extent statements applied , visual-object imagery ability (e.g., “imagine friend’s face, perfectly clear bright image”), visuo-spatial imagery ability (e.g., “images tend schematic representations things events rather detailed images”) verbal strategies processing information (e.g., “remember scene, use verbal descriptions rather mental images”), 5-point scale ranging 1 (“Totally disagree”) 5 (“Totally agree”). sub-scale (object, spatial, verbal) comprises 15 items whose values added together obtain score ranging 15 75. Cronbach’s α\\alpha object, spatial verbal scales .83, .79 .74 respectively (Blazhenkova & Kozhevnikov, 2009). mental imagery multi-sensory experience limited vision, Plymouth Sensory Imagery Questionnaire (Psi-Q, Andrade et al., 2014) used assess imagery vividness across various sensory modalities. Psi-Q (short form) comprises seven sets three items following modalities: Vision, Hearing, Smell, Taste, Touch, Bodily Sensation Emotional Feeling. set heading “Imagine appearance …”} three items. Participants asked rate image 11-point scale anchored 0 (“image ”) 10 (“vivid real life”), thus yielding scores ranging 0 33 modality. Cronbach’s α\\alpha 21-item Psi-Q .91 (Andrade et al., 2014). Raven Standard Progressive Matrices (hereinafter called Raven matrices, Raven & Court, 1938) widely-used assessment estimate fluid intelligence (non-verbal visual perception ability) abstract reasoning (analogical deductive reasoning abilities). Raven matrices contains 60 items divided five sets. question consists completing missing figure matrix 3×33 \\times 3 figures extracting following logical rules underlying organisation matrices. Items increasing difficulty. end set, difficulty decreases logical rule changes, successive sets increasing difficulty. shortened clinical version two short forms 9 items developed Bilker et al. (2012) used, predicting 60-item score good accuracy. short forms correlations r=.98r = .98 long form, respective Cronbach’s α\\alpha .80 .83. shortened version represents 70% reduction number items administered test-taking time, psychometric characteristics similar full form (Bilker et al., 2012). Spatial Reasoning Instrument (SRI, Ramful et al., 2017) 30-item test measuring spatial ability along three constructs: mental rotation, spatial orientation, spatial visualisation. test showed good validity psychometric properties three areas: () exploratory factor analysis subscales (mental rotation, spatial orientation, spatial visualisation), (b) Rasch analysis item reliability within construct, (c) significant correlations (r∈[.33,.62]r \\[.33, .62]) person separation reliability four existing well-regarded instruments measuring spatial reasoning, Card Rotation Test, Cube Comparison Test, Paper Folding Test [Ekstrom (1976)] Perspective Taking (Spatial Orientation) Test (Kozhevnikov & Hegarty, 2001). internal reliability (Cronbach’s α\\alpha) SRI .85. Similarities sub-test Weschler Adult Intelligence Scale (WAIS-IV, Wechsler et al., 2008) well-known assessment estimate verbal comprehension abilities. Specifically, test assesses verbal concept formation verbal abstract reasoning. comprises 18 pairs words participant identify underlying qualitative relationship (e.g., “DREAM REALITY similar?”). Accurate answers (rated according standardized response scale) receive two points, approximate answers one point, vague incorrect answers zero, giving maximum score 36. three zero scores, task stops. Due internet-based nature experiment, participants passed items, scoring answers stopped three incorrect answers. scoring carried manually, using double scoring first two authors article, blind groups participants. participants performed fifth percentile Similarities WAIS-IV sub-test (score ≥\\geq 12/36), thereby confirming none participants presented deficit semantic oral language skills. Reverse Corsi blocks spatial memory span task (Gibeau, 2021) assessing visuo-spatial working memory. task consists presenting participant grid blocks frame, displaying sequence blocks (blocks changing colours turn), rate one per second, asking participant recall reverse order, last block first. task began short sequence three blocks, increasing success decreasing two failures, fixed total 14 trials. average number blocks recalled correctly correct position retained score task. reverse digit span verbal memory span task assessing verbal working memory (Blackburn & Benton, 1957). task involves presenting numbers rate 1 per second, asking participant recall last first. task begins short sequence three digits, lengthens success decreases two failures, total 14 trials. average number digits recalled correctly correct position retained score task. Wisconsin Card Sorting Test (WCST, Heaton & Staff, 1993) widely used test set-shifting ability developed measure flexibility human thought ability shift cognitive strategy response changing contingencies. WCST designed measure executive functioning including attentional set shifting, task/rule switching reversal, working memory abilities. assessment requires participants sort 64 cards according color (red, blue, yellow green), shape (cross, circle, triangle star) number figures (one, two, three four). course task, sorting rule discreetly changes color shape number figures, without participants informed. Participants must modify predictions choices accordingly sort cards according new sorting rule: receive feedback response (correct incorrect), enable improve implicit rule extraction (Nelson, 1976). final score used percentage correct sorts 64 trials. WCST, scored according percentage (number) correct sorts, exhibits satisfying split-half reliability (Spearman-Brown r = .90, Kopp et al., 2021). reading comprehension task assesses explicit literal comprehension inferential comprehension skills designed assessment adult readers (Brèthes et al., 2022). Reading comprehension complex cognitive activity involves number skills including word recognition skills, grammar, semantic general knowledge, working memory reasoning skills well inference-making abilities. reading comprehension task composed three texts drawn French daily newspaper Le Monde, dealing destruction Great Barrier Reef various causes. participant read text without time constraints, answer eight questions: four questions explicit literal comprehension four inferential questions comprehension implicit information texts, among two examined text-connecting inferences two examined knowledge-based inferences. text-connecting inference skills required participants integrate text information order establish local cohesiveness, knowledge-based inference skills required participants establish links text content personal knowledge. questions also divided two question formats: open questions multiple-choice questions. Participants allowed refer text answering questions. , test contained 20 questions whose answers scored experimenter, 2 points complete answers, 1 point incomplete answers 0 incorrect answers. maximum score therefore 40 points. scoring carried manually, using double scoring first two authors present article, blind groups participants. Cronbach’s α\\alpha task 0.78. experiment administered online via JATOS server (Lange et al., 2015). programmed using SurveyJS jsPsych (Leeuw et al., 2023), open-source JavaScript libraries dedicated creation questionnaires experiments respectively, well OpenSesame (Mathôt et al., 2012), graphical interface construction behavioural experiments. link experiment emailed individually volunteer participant used per participant. participants subjected study design task sequence. first questionnaires, participants gave consent, demographic data collected (first language, age, gender, occupation, education field study, vision). Due length protocol (Median time spent = 84.58 min, Median Absolute Deviation = 27.51 min), experiment structured instructions accompanied pages explanations reinforce engagement focus (e.g., inviting people “dive minds” “test abilities”). text mentioned word aphantasia, avoid stigma, bias preconceived ideas specifically associated term (see Cabbai et al., 2023; Monzel, Dance, et al., 2023). experiment started VVIQ, followed Raven matrices, WCST, OSIVQ, SRI, reverse Corsi blocks, Similarities test, Reading comprehension task, reverse digit span, ended Psi-Q. None tasks time limit, participants instructed respond soon answer maintaining accuracy, aim reducing total duration experiment . However, given experiment long, participants monitored due online format, instructions place particular emphasis speed response key aspect, response times analysed. analyses conducted using R statistical language (R Core Team, 2024) RStudio (Posit team, 2025). Data curation handled R packages tidyverse collection (Wickham et al., 2019). visualisations produced packages ggplot2 (Wickham, 2016), factoextra (Kassambara & Mundt, 2020), see (Lüdecke et al., 2021), superb (Cousineau et al., 2021) patchwork (Pedersen, 2024). Bayesian modelling used throughout analyses conducted using R packages rstanarm (Gabry & Goodrich, 2024), BayesFactor (Morey & Rouder, 2024) bayestestR (Makowski et al., 2019), using default weakly informative priors. R package emmeans (Lenth, 2024) used marginal estimates contrast analyses. tests, statistic reported, log(BF10)log(BF_{10}), quantifies relative “weight evidence” favour hypothesis H1H_{1} (e.g., effect factor), null hypothesis H0H_{0}(Good, 1985). According Jeffrey’s scale thresholds (see Kass & Raftery, 1995), log(BF10)∈[0;0.5[log(BF_{10}) \\[0;0.5[ = “Barely worth mentioning”; ∈[0.5;1[\\[0.5;1[ = “Substantial evidence”; ∈[1;2[\\[1;2[ = “Strong evidence”; ∈[2;+∞[\\[2;+\\infty[ = “Decisive evidence”. negative thresholds apply weight evidence favour H0H_0.","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/articles/manuscript.html","id":"participants","dir":"Articles","previous_headings":"","what":"Participants","title":"Reproducible manuscript","text":"Participants French speakers, normal corrected vision none participants reported known reading disorders. recruited online groups unrelated mental imagery (social networks, French cognitive science information network, etc.) groups dedicated aphantasia visual imagery. study link sent participants volunteered contacting team email. study carried following recommendations French Law (Loi Jardé n◦2012- 300), accordance ethical standards institutional research committee Declaration Helsinki later amendments. Informed consent obtained individual participants included study . Participation without compensation. study exploratory, sample size determined priori. data participants completed tasks included analyses. Participants skipped task extremely fast removed data. 1200 people opened link study, 96 completed tasks, making final sample. questionnaire statistics detailed results part .","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/articles/manuscript.html","id":"materials","dir":"Articles","previous_headings":"","what":"Materials","title":"Reproducible manuscript","text":"Vividness Visual Imagery Questionnaire (VVIQ, Marks, 1973) used assess visual imagery ability. VVIQ 16-item self-report scale asks participants imagine person several scenes rate vividness mental images using 5-point scale ranging 1 (“imagery , just know ’re thinking object”) 5 (“Perfectly clear vivid normal vision”). Scores range 16 80. total score 32, often used threshold define aphantasia (Dawes et al., 2020; Keogh et al., 2021; e.g., dancePrevalenceAphantasiaImagery2022?; speedRoleVisualImagery2024?), equivalent score 2 (“vague faint”) item questionnaire. internal reliability (Cronbach’s α\\alpha) VVIQ .88 (McKelvie, 1995). Object-Spatial Imagery Verbal Questionnaire (OSIVQ, Blazhenkova & Kozhevnikov, 2009) used evaluate imagery strategies cognitive styles. OSIVQ 45-item scale asks participants indicate extent statements applied , visual-object imagery ability (e.g., “imagine friend’s face, perfectly clear bright image”), visuo-spatial imagery ability (e.g., “images tend schematic representations things events rather detailed images”) verbal strategies processing information (e.g., “remember scene, use verbal descriptions rather mental images”), 5-point scale ranging 1 (“Totally disagree”) 5 (“Totally agree”). sub-scale (object, spatial, verbal) comprises 15 items whose values added together obtain score ranging 15 75. Cronbach’s α\\alpha object, spatial verbal scales .83, .79 .74 respectively (Blazhenkova & Kozhevnikov, 2009). mental imagery multi-sensory experience limited vision, Plymouth Sensory Imagery Questionnaire (Psi-Q, Andrade et al., 2014) used assess imagery vividness across various sensory modalities. Psi-Q (short form) comprises seven sets three items following modalities: Vision, Hearing, Smell, Taste, Touch, Bodily Sensation Emotional Feeling. set heading “Imagine appearance …”} three items. Participants asked rate image 11-point scale anchored 0 (“image ”) 10 (“vivid real life”), thus yielding scores ranging 0 33 modality. Cronbach’s α\\alpha 21-item Psi-Q .91 (Andrade et al., 2014). Raven Standard Progressive Matrices (hereinafter called Raven matrices, Raven & Court, 1938) widely-used assessment estimate fluid intelligence (non-verbal visual perception ability) abstract reasoning (analogical deductive reasoning abilities). Raven matrices contains 60 items divided five sets. question consists completing missing figure matrix 3×33 \\times 3 figures extracting following logical rules underlying organisation matrices. Items increasing difficulty. end set, difficulty decreases logical rule changes, successive sets increasing difficulty. shortened clinical version two short forms 9 items developed Bilker et al. (2012) used, predicting 60-item score good accuracy. short forms correlations r=.98r = .98 long form, respective Cronbach’s α\\alpha .80 .83. shortened version represents 70% reduction number items administered test-taking time, psychometric characteristics similar full form (Bilker et al., 2012). Spatial Reasoning Instrument (SRI, Ramful et al., 2017) 30-item test measuring spatial ability along three constructs: mental rotation, spatial orientation, spatial visualisation. test showed good validity psychometric properties three areas: () exploratory factor analysis subscales (mental rotation, spatial orientation, spatial visualisation), (b) Rasch analysis item reliability within construct, (c) significant correlations (r∈[.33,.62]r \\[.33, .62]) person separation reliability four existing well-regarded instruments measuring spatial reasoning, Card Rotation Test, Cube Comparison Test, Paper Folding Test [Ekstrom (1976)] Perspective Taking (Spatial Orientation) Test (Kozhevnikov & Hegarty, 2001). internal reliability (Cronbach’s α\\alpha) SRI .85. Similarities sub-test Weschler Adult Intelligence Scale (WAIS-IV, Wechsler et al., 2008) well-known assessment estimate verbal comprehension abilities. Specifically, test assesses verbal concept formation verbal abstract reasoning. comprises 18 pairs words participant identify underlying qualitative relationship (e.g., “DREAM REALITY similar?”). Accurate answers (rated according standardized response scale) receive two points, approximate answers one point, vague incorrect answers zero, giving maximum score 36. three zero scores, task stops. Due internet-based nature experiment, participants passed items, scoring answers stopped three incorrect answers. scoring carried manually, using double scoring first two authors article, blind groups participants. participants performed fifth percentile Similarities WAIS-IV sub-test (score ≥\\geq 12/36), thereby confirming none participants presented deficit semantic oral language skills. Reverse Corsi blocks spatial memory span task (Gibeau, 2021) assessing visuo-spatial working memory. task consists presenting participant grid blocks frame, displaying sequence blocks (blocks changing colours turn), rate one per second, asking participant recall reverse order, last block first. task began short sequence three blocks, increasing success decreasing two failures, fixed total 14 trials. average number blocks recalled correctly correct position retained score task. reverse digit span verbal memory span task assessing verbal working memory (Blackburn & Benton, 1957). task involves presenting numbers rate 1 per second, asking participant recall last first. task begins short sequence three digits, lengthens success decreases two failures, total 14 trials. average number digits recalled correctly correct position retained score task. Wisconsin Card Sorting Test (WCST, Heaton & Staff, 1993) widely used test set-shifting ability developed measure flexibility human thought ability shift cognitive strategy response changing contingencies. WCST designed measure executive functioning including attentional set shifting, task/rule switching reversal, working memory abilities. assessment requires participants sort 64 cards according color (red, blue, yellow green), shape (cross, circle, triangle star) number figures (one, two, three four). course task, sorting rule discreetly changes color shape number figures, without participants informed. Participants must modify predictions choices accordingly sort cards according new sorting rule: receive feedback response (correct incorrect), enable improve implicit rule extraction (Nelson, 1976). final score used percentage correct sorts 64 trials. WCST, scored according percentage (number) correct sorts, exhibits satisfying split-half reliability (Spearman-Brown r = .90, Kopp et al., 2021). reading comprehension task assesses explicit literal comprehension inferential comprehension skills designed assessment adult readers (Brèthes et al., 2022). Reading comprehension complex cognitive activity involves number skills including word recognition skills, grammar, semantic general knowledge, working memory reasoning skills well inference-making abilities. reading comprehension task composed three texts drawn French daily newspaper Le Monde, dealing destruction Great Barrier Reef various causes. participant read text without time constraints, answer eight questions: four questions explicit literal comprehension four inferential questions comprehension implicit information texts, among two examined text-connecting inferences two examined knowledge-based inferences. text-connecting inference skills required participants integrate text information order establish local cohesiveness, knowledge-based inference skills required participants establish links text content personal knowledge. questions also divided two question formats: open questions multiple-choice questions. Participants allowed refer text answering questions. , test contained 20 questions whose answers scored experimenter, 2 points complete answers, 1 point incomplete answers 0 incorrect answers. maximum score therefore 40 points. scoring carried manually, using double scoring first two authors present article, blind groups participants. Cronbach’s α\\alpha task 0.78.","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/articles/manuscript.html","id":"questionnaires","dir":"Articles","previous_headings":"2 Methods","what":"Questionnaires","title":"Reproducible manuscript","text":"Vividness Visual Imagery Questionnaire (VVIQ, Marks, 1973) used assess visual imagery ability. VVIQ 16-item self-report scale asks participants imagine person several scenes rate vividness mental images using 5-point scale ranging 1 (“imagery , just know ’re thinking object”) 5 (“Perfectly clear vivid normal vision”). Scores range 16 80. total score 32, often used threshold define aphantasia (Dawes et al., 2020; Keogh et al., 2021; e.g., dancePrevalenceAphantasiaImagery2022?; speedRoleVisualImagery2024?), equivalent score 2 (“vague faint”) item questionnaire. internal reliability (Cronbach’s α\\alpha) VVIQ .88 (McKelvie, 1995). Object-Spatial Imagery Verbal Questionnaire (OSIVQ, Blazhenkova & Kozhevnikov, 2009) used evaluate imagery strategies cognitive styles. OSIVQ 45-item scale asks participants indicate extent statements applied , visual-object imagery ability (e.g., “imagine friend’s face, perfectly clear bright image”), visuo-spatial imagery ability (e.g., “images tend schematic representations things events rather detailed images”) verbal strategies processing information (e.g., “remember scene, use verbal descriptions rather mental images”), 5-point scale ranging 1 (“Totally disagree”) 5 (“Totally agree”). sub-scale (object, spatial, verbal) comprises 15 items whose values added together obtain score ranging 15 75. Cronbach’s α\\alpha object, spatial verbal scales .83, .79 .74 respectively (Blazhenkova & Kozhevnikov, 2009). mental imagery multi-sensory experience limited vision, Plymouth Sensory Imagery Questionnaire (Psi-Q, Andrade et al., 2014) used assess imagery vividness across various sensory modalities. Psi-Q (short form) comprises seven sets three items following modalities: Vision, Hearing, Smell, Taste, Touch, Bodily Sensation Emotional Feeling. set heading “Imagine appearance …”} three items. Participants asked rate image 11-point scale anchored 0 (“image ”) 10 (“vivid real life”), thus yielding scores ranging 0 33 modality. Cronbach’s α\\alpha 21-item Psi-Q .91 (Andrade et al., 2014).","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/articles/manuscript.html","id":"tasks","dir":"Articles","previous_headings":"2 Methods","what":"Tasks","title":"Reproducible manuscript","text":"Raven Standard Progressive Matrices (hereinafter called Raven matrices, Raven & Court, 1938) widely-used assessment estimate fluid intelligence (non-verbal visual perception ability) abstract reasoning (analogical deductive reasoning abilities). Raven matrices contains 60 items divided five sets. question consists completing missing figure matrix 3×33 \\times 3 figures extracting following logical rules underlying organisation matrices. Items increasing difficulty. end set, difficulty decreases logical rule changes, successive sets increasing difficulty. shortened clinical version two short forms 9 items developed Bilker et al. (2012) used, predicting 60-item score good accuracy. short forms correlations r=.98r = .98 long form, respective Cronbach’s α\\alpha .80 .83. shortened version represents 70% reduction number items administered test-taking time, psychometric characteristics similar full form (Bilker et al., 2012). Spatial Reasoning Instrument (SRI, Ramful et al., 2017) 30-item test measuring spatial ability along three constructs: mental rotation, spatial orientation, spatial visualisation. test showed good validity psychometric properties three areas: () exploratory factor analysis subscales (mental rotation, spatial orientation, spatial visualisation), (b) Rasch analysis item reliability within construct, (c) significant correlations (r∈[.33,.62]r \\[.33, .62]) person separation reliability four existing well-regarded instruments measuring spatial reasoning, Card Rotation Test, Cube Comparison Test, Paper Folding Test [Ekstrom (1976)] Perspective Taking (Spatial Orientation) Test (Kozhevnikov & Hegarty, 2001). internal reliability (Cronbach’s α\\alpha) SRI .85. Similarities sub-test Weschler Adult Intelligence Scale (WAIS-IV, Wechsler et al., 2008) well-known assessment estimate verbal comprehension abilities. Specifically, test assesses verbal concept formation verbal abstract reasoning. comprises 18 pairs words participant identify underlying qualitative relationship (e.g., “DREAM REALITY similar?”). Accurate answers (rated according standardized response scale) receive two points, approximate answers one point, vague incorrect answers zero, giving maximum score 36. three zero scores, task stops. Due internet-based nature experiment, participants passed items, scoring answers stopped three incorrect answers. scoring carried manually, using double scoring first two authors article, blind groups participants. participants performed fifth percentile Similarities WAIS-IV sub-test (score ≥\\geq 12/36), thereby confirming none participants presented deficit semantic oral language skills. Reverse Corsi blocks spatial memory span task (Gibeau, 2021) assessing visuo-spatial working memory. task consists presenting participant grid blocks frame, displaying sequence blocks (blocks changing colours turn), rate one per second, asking participant recall reverse order, last block first. task began short sequence three blocks, increasing success decreasing two failures, fixed total 14 trials. average number blocks recalled correctly correct position retained score task. reverse digit span verbal memory span task assessing verbal working memory (Blackburn & Benton, 1957). task involves presenting numbers rate 1 per second, asking participant recall last first. task begins short sequence three digits, lengthens success decreases two failures, total 14 trials. average number digits recalled correctly correct position retained score task. Wisconsin Card Sorting Test (WCST, Heaton & Staff, 1993) widely used test set-shifting ability developed measure flexibility human thought ability shift cognitive strategy response changing contingencies. WCST designed measure executive functioning including attentional set shifting, task/rule switching reversal, working memory abilities. assessment requires participants sort 64 cards according color (red, blue, yellow green), shape (cross, circle, triangle star) number figures (one, two, three four). course task, sorting rule discreetly changes color shape number figures, without participants informed. Participants must modify predictions choices accordingly sort cards according new sorting rule: receive feedback response (correct incorrect), enable improve implicit rule extraction (Nelson, 1976). final score used percentage correct sorts 64 trials. WCST, scored according percentage (number) correct sorts, exhibits satisfying split-half reliability (Spearman-Brown r = .90, Kopp et al., 2021). reading comprehension task assesses explicit literal comprehension inferential comprehension skills designed assessment adult readers (Brèthes et al., 2022). Reading comprehension complex cognitive activity involves number skills including word recognition skills, grammar, semantic general knowledge, working memory reasoning skills well inference-making abilities. reading comprehension task composed three texts drawn French daily newspaper Le Monde, dealing destruction Great Barrier Reef various causes. participant read text without time constraints, answer eight questions: four questions explicit literal comprehension four inferential questions comprehension implicit information texts, among two examined text-connecting inferences two examined knowledge-based inferences. text-connecting inference skills required participants integrate text information order establish local cohesiveness, knowledge-based inference skills required participants establish links text content personal knowledge. questions also divided two question formats: open questions multiple-choice questions. Participants allowed refer text answering questions. , test contained 20 questions whose answers scored experimenter, 2 points complete answers, 1 point incomplete answers 0 incorrect answers. maximum score therefore 40 points. scoring carried manually, using double scoring first two authors present article, blind groups participants. Cronbach’s α\\alpha task 0.78.","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/articles/manuscript.html","id":"experimental-design-and-procedure","dir":"Articles","previous_headings":"","what":"Experimental design and procedure","title":"Reproducible manuscript","text":"experiment administered online via JATOS server (Lange et al., 2015). programmed using SurveyJS jsPsych (Leeuw et al., 2023), open-source JavaScript libraries dedicated creation questionnaires experiments respectively, well OpenSesame (Mathôt et al., 2012), graphical interface construction behavioural experiments. link experiment emailed individually volunteer participant used per participant. participants subjected study design task sequence. first questionnaires, participants gave consent, demographic data collected (first language, age, gender, occupation, education field study, vision). Due length protocol (Median time spent = 84.58 min, Median Absolute Deviation = 27.51 min), experiment structured instructions accompanied pages explanations reinforce engagement focus (e.g., inviting people “dive minds” “test abilities”). text mentioned word aphantasia, avoid stigma, bias preconceived ideas specifically associated term (see Cabbai et al., 2023; Monzel, Dance, et al., 2023). experiment started VVIQ, followed Raven matrices, WCST, OSIVQ, SRI, reverse Corsi blocks, Similarities test, Reading comprehension task, reverse digit span, ended Psi-Q. None tasks time limit, participants instructed respond soon answer maintaining accuracy, aim reducing total duration experiment . However, given experiment long, participants monitored due online format, instructions place particular emphasis speed response key aspect, response times analysed.","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/articles/manuscript.html","id":"analyses","dir":"Articles","previous_headings":"","what":"Analyses","title":"Reproducible manuscript","text":"analyses conducted using R statistical language (R Core Team, 2024) RStudio (Posit team, 2025). Data curation handled R packages tidyverse collection (Wickham et al., 2019). visualisations produced packages ggplot2 (Wickham, 2016), factoextra (Kassambara & Mundt, 2020), see (Lüdecke et al., 2021), superb (Cousineau et al., 2021) patchwork (Pedersen, 2024). Bayesian modelling used throughout analyses conducted using R packages rstanarm (Gabry & Goodrich, 2024), BayesFactor (Morey & Rouder, 2024) bayestestR (Makowski et al., 2019), using default weakly informative priors. R package emmeans (Lenth, 2024) used marginal estimates contrast analyses. tests, statistic reported, log(BF10)log(BF_{10}), quantifies relative “weight evidence” favour hypothesis H1H_{1} (e.g., effect factor), null hypothesis H0H_{0}(Good, 1985). According Jeffrey’s scale thresholds (see Kass & Raftery, 1995), log(BF10)∈[0;0.5[log(BF_{10}) \\[0;0.5[ = “Barely worth mentioning”; ∈[0.5;1[\\[0.5;1[ = “Substantial evidence”; ∈[1;2[\\[1;2[ = “Strong evidence”; ∈[2;+∞[\\[2;+\\infty[ = “Decisive evidence”. negative thresholds apply weight evidence favour H0H_0.","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/articles/manuscript.html","id":"results","dir":"Articles","previous_headings":"","what":"Results","title":"Reproducible manuscript","text":"final sample comprised 96 participants (MageM_{age} = 32.5, SDageSD_{age} = 11.3, rangeage_{age} = [19, 65], 74 females, 21 males, 1 another gender). widely used criterion studies aphantasia identify condition score inferior 32 VVIQ, threshold often used literature (Dawes et al., 2020; Keogh et al., 2021; e.g., dancePrevalenceAphantasiaImagery2022?; speedRoleVisualImagery2024?). 45 individuals aphantasia sample (MVVIQM_{VVIQ} = 18.3, SDVVIQSD_{VVIQ} = 4.2, MageM_{age} = 33.8, SDageSD_{age} = 10.6, 37 females, 8 males) 51 controls (MVVIQM_{VVIQ} = 58.1, SDVVIQSD_{VVIQ} = 10.8, MageM_{age} = 31.4, SDageSD_{age} = 11.8, 37 females, 13 males, 1 another gender). Participants’ level education, field study, occupation analysed detect association grouping factor. Levels education coded using equivalent French levels International Standard Classification Education (ISCED), .e., Upper secondary, Post-secondary, Bachelor, Master, Doctorate. Fields study coded according 10 broad categories defined ISCED-F 2013 (ISCED: Fields Education Training). Occupations coded according sub-major groups International Standard Classification Occupations (ISCO-08) appropriate level precision given sample size. Nine occupational groups identified sample. Bayes factors independence calculated evaluate association groups demographic variable (see Gûnel & Dickey, 1974). tests found evidence relationship groups levels education (log(BF10)log(BF_{10}) = -4.88), groups fields study (log(BF10)log(BF_{10}) = -5.41), groups occupation (log(BF10)log(BF_{10}) = -4.37). measured variables scores VVIQ, three OSIVQ scales, seven Psi-Q scales, Raven matrices, SRI, Similarities Test, reverse spatial verbal spans, WCST Reading comprehension task. Linear models fitted various variables model participant groups categorical predictors age continuous covariate control potential influence latter. Contrast analyses thereafter conducted assess differences groups. score differences (hereinafter referred Δ\\Delta) 95% Credible Intervals reported Table 1 along log(BF10)log(BF_{10}) quantifying weight evidence favour non-null difference groups. Individuals aphantasia lower scores controls visual imagery scales (VVIQ: log(BF10)log(BF_{10}) = 64.33; OSIVQ-Object: log(BF10)log(BF_{10}) = 37.94; Psi-Q Visual: log(BF10)log(BF_{10}) = 58.94), also sensory imaging modalities evaluated Psi-Q (log(BF10)∈[14;31]log(BF_{10}) \\[14; 31] modalities). means contrasts groups represented distributions Figure 1. Apart sensory imagery, evidence found favour difference groups verbal scale OSIVQ, individuals aphantasia scoring higher controls (Δ\\Delta = -6.39, 95% CrI = [-10.12, -2.53], log(BF10)log(BF_{10}) = 1.63). differences groups found variables: statistical analyses showed evidence difference spatial scale OSIVQ (log(BF10)log(BF_{10}) = -0.7), differences Raven matrices scores (log(BF10)log(BF_{10}) = -1.3), SRI scores (log(BF10)log(BF_{10}) = -2.2), spatial span (log(BF10)log(BF_{10}) = -1.01), digit span (log(BF10)log(BF_{10}) = -3.28), Similarities test scores (log(BF10)log(BF_{10}) = -2.68), Reading comprehension scores (log(BF10)log(BF_{10}) = -1.94) WCST scores (log(BF10)log(BF_{10}) = -3.22). Figure 1: Standardised scores two VVIQ groups questionnaires tasks. scores rescaled 0 1 represented scale. coloured shapes represent distribution scores group. coloured dots represent mean group, bars represent standard deviations. stars represent weight evidence thresholds favour effect Group: * = ‘Substantial evidence’, ** = ‘Strong evidence’, *** = ‘Decisive evidence’. VVIQ model—.e., division sample two VVIQ groups individuals aphantasia controls—therefore little explanatory power task performance. However, large inter-individual variances observed various outcomes, evidenced spread outcomes’ distributions several bimodal distributions (e.g., distributions OSIVQ-Verbal, SRI, Reading comprehension scores, see Figure 1). unexplained differences suggested existence underlying structure sample, thus requiring better model relevant groups account light data. studied hypothesis searching sub-groups sample using data-driven unsupervised clustering. selection relevant variables clustering essential good model fit interpretation results (Fop & Murphy, 2018; Zakharov, 2016). adequate number dimensions (variables) given sample size also crucial increase quality clustering (Psutka & Psutka, 2019). identification reduction redundant variables particularly important, distort relative weight latent variable clustering process. two variables represent concept, concept represented twice data hence get twice weight variables. final solution skewed direction concept, considerably compromise relevance model understanding variable importance (Kyriazos & Poga, 2023). present analysis, issue particularly affected sensory imagery, represented nine highly correlated variables (VVIQ, OSIVQ-Object, seven Psi-Q modalities, Pearson’s r∈[0.65,0.94]r \\[0.65, 0.94] every pairwise correlation) likely reflect similar constructs, opposed remaining nine variables. Several methods exist deal multicollinearity problems. low-dimensional setting, chose merge variables averaging maintain interpretability enhancing stability model (Kyriazos & Poga, 2023). choose variables merge, analysed relationships variables using partial correlations. Partial correlations measure degree association two variables controlling effect potentially confounding covariates (Abdi, 2007). procedure allows identify strongest unbiased links variables prevents misinterpretation spurious correlations. computed partial correlations 18 variables (see Figure 2) chose merge significantly correlated variables Bonferroni correction (multiplying p-values number comparisons). resulted creation four new reduced variables. First, three subscales related visual imagery, .e., VVIQ, OSIVQ-Object Psi-Q Visual, associated (VVIQ - Psi-Q Visual: r = 0.67, p << 0.001; OSIVQ-Object - Psi-Q Visual: r = 0.36, p << 0.05). standardised 0 1, weighted number items (16, 15 3 respectively) merged single “Visual imagery” variable obtain balanced continuous measure imagery possible. Second, OSIVQ-Spatial score SRI, .e., subjective objective spatial imagery, associated (r = 0.36, p << 0.05). standardised merged single “Spatial imagery” variable. Third, five Psi-Q sensory imagery subscales (Smell, Taste, Touch, Sensations Feelings) associated (Psi-Q Smell - Taste: r = 0.47, p << 0.001; Taste - Touch: r = 0.38, p << 0.05; Touch - Sensations: r = 0.41, p << 0.01; Sensations - Feelings: r = 0.39, p << 0.05). standardised merged single “Sensory imagery” variable. Fourth, score Raven matrices Digit span associated (r = 0.37, p << 0.05). standardised merged common “Raven + Digit” variable. Based link established reverse digit span measures intellectual executive functions (Groeger et al., 1999), interpreted variable theoretically proxy general cognitive performance. Figure 2: Correlation matrix undirected graph representing partial correlations 18 variables. stars matrix represent p-value thresholds: * : p << 0.05, ** : p << 0.01, *** : p << 0.001, Bonferroni correction. links graph represent significant partial correlations. coloured (non-black) nodes highlight variables used clustering, result merging several correlated variables. Light blue: Visual imagery; dark blue: Sensory imagery; light orange: Spatial imagery; green: Verbal strategies; pink: Raven + Digit; dark orange: Verbal reasoning. Finally, three variables included clustering. Psi-Q Auditory Psi-Q subscale associated variables. comprises three items, variable included clustering avoid giving undue importance. WCST Reading comprehension scores used either, tasks designed evaluate higher-level abilities operate integrated levels cognition. Executive functioning reading comprehension inextricably involve mix working memory, reasoning attention (Heaton & Staff, 1993; Kongs et al., 2000; Suggate & Lenhard, 2022), likely integrate many redundant processes assessments. Instead, variables used posteriori testing variables assess generalisability cluster model external variables, .e., related sensory imagery subscale Psi-Q Auditory, complex cognitive tasks two. decision planned study, decided conducting cluster analysis based variable reduction theoretical considerations. entire selection procedure allowed reduce variable space seven dimensions, estimated Psutka & Psutka (2019) yield good accuracy parameter recovery model-based clustering (see next section) sample N = 96. result, variables modified keep much information possible. sake clarity, several scores renamed reflect assess. OSIVQ-Verbal score identified propensity use Verbal strategies information processing, line definition sub-scale (see Blazhenkova & Kozhevnikov, 2009). Similarities test score identified Verbal Reasoning variable. clustering process therefore conducted seven following variables: Visual imagery, Sensory imagery, Spatial imagery, Verbal strategies, Raven + Digit span, Verbal reasoning Spatial span. model variables using scale, data normalized 0 1 respective scales, recommended Zakharov (2016). model-based method chosen clustering. approach, clustering aims modelling distributions mixtures multivariate Gaussian distributions (Steinley & Brusco, 2011). Finite Gaussian mixture models (GMM) attempt determine underlying population groups produced observed data, cluster distribution centre spread. resulting model used compute probability observation belonging cluster. Although discrete (k-means) hierarchical clustering methods frequently used psychology (Zakharov, 2016), probabilistic mixture modelling approaches proven powerful parsimonious partially overlapping, non-spherical, multivariate normal distributions, small sample sizes, common psychology experiments (Dalmaijer et al., 2022). Given little information available clusters, estimation GMM proceeds steps, alternating (1) estimating posterior probability observation belonging cluster fixed set parameters (2) updating estimates parameters fixing probability cluster membership observation (Steinley & Brusco, 2011). iterative procedure continues model converges stable clusters. standard method estimation expectation-maximisation algorithm (EM, Dempster et al., 1977)1. present study, mclust R package (Scrucca et al., 2023) used conduct GMM clustering. estimation procedure mixture clusters GMM requires knowledge number clusters distributional form. determination parameters done using Bayesian Information Criterion (BIC) implemented mclust package. Figure 3: Comparison goodness fit different mixture models used clustering function model type number components. high BIC indicates good model fit. three-letter acronyms describe components mixture models. first letter describes volume components, second shape last orientation. E = equal, V = variable. Acronyms ending ‘II’ indicate mixtures spherical components, ending ‘’ indicate mixtures diagonal components without ‘’ indicate mixtures ellipsoidal components. generally accepted rules regarding minimum sample sizes clustering procedures. model-based clustering procedures Dalmaijer et al. (2022) recommended N = 20 N = 30 per expected cluster medium large effect sizes (.e., cluster separation), translate two four clusters sample. Given present dataset, comparison various GMM types different number clusters using BIC showed best solution model three ellipsoidal clusters varying shapes, equal volume orientations (EVE model, see Figure 3). profiles three clusters obtained presented Figure 4 (left panel). Cluster made exclusively individuals aphantasia (NAN_A = 32), Cluster B mixed (NBN_B = 30), comprising 17 controls 13 individuals aphantasia, Cluster C composed solely control participants (NCN_C = 34). Bayes factors independence found association clusters levels education (log(BF10)log(BF_{10}) = -7.44), clusters fields study (log(BF10)log(BF_{10}) = -6.06), clusters occupation (log(BF10)log(BF_{10}) = -3.88). Figure 4: Profiles clusters obtained model-based clustering. Left: Polar plot representing standardised means (points) standard errors (error bars) three clusters seven clustering variables three external variables (Auditory imagery, WCST Reading comprehension). Cluster exclusively composed individuals aphantasia, Cluster C exclusively composed control participants, Cluster B mixed. Right: polar plot Cluster B divided two sub-clusters, ‘B-Aphant.’ 13 individuals aphantasia B, ‘B-Control’ 17 control participants B. Cluster scores modelled clusters predictors using linear Bayesian modelling described modelling variables groups. detailed pairwise differences clusters 95% Credible Intervals reported Table 2 along weights evidence favour differences clusters. three clusters distinctive features visual, sensory, spatial verbal dimensions cognitive profiles. seen, Visual Sensory imagery, Controls (cluster C) much higher scores mixed cluster (cluster B) higher scores Aphantasic cluster (cluster ; log(BF10)≥log(BF_{10}) \\geq 3.99). Cluster B higher scores two clusters Spatial imagery (log(BF10)≥log(BF_{10}) \\geq 5.52), differ (log(BF10)log(BF_{10}) = -1.74). turn, cluster higher scores two Verbal strategies (log(BF10)≥log(BF_{10}) \\geq 4.31), B C differ (log(BF10)log(BF_{10}) = -3.19). Else, cluster B outperformed cluster C verbal reasoning spatial span (log(BF10)≥log(BF_{10}) \\geq 3.33), differences found cluster two scores (log(BF10)≤log(BF_{10}) \\leq 0.16). Finally, Raven + Digit span variable, differences clusters negligible (log(BF10)≤log(BF_{10}) \\leq -2.2). also modelled variables excluded clustering procedure, .e., Auditory imagery, WCST reading comprehension scores, assess cluster patterns transferred external variables. seen bottom Table 2. imagery patterns maintained Auditory imagery, cluster C scored higher B (log(BF10)log(BF_{10}) = 2.33), turn scored higher (log(BF10)log(BF_{10}) = 11.37). However, although mean cluster scores WCST reading comprehension followed trend cognitive tasks (.e. B >> >> C — WCST: MBM_{B} (SDBSD_{B}) = 0.66 (0.14); MAM_{} (SDASD_{}) = 0.65 (0.13); MCM_{C} (SDCSD_{C}) = 0.6 (0.16) — Reading comprehension: MBM_{B} (SDBSD_{B}) = 0.63 (0.2); MAM_{} (SDASD_{}) = 0.6 (0.16); MCM_{C} (SDCSD_{C}) = 0.52 (0.23)), evidence absence differences clusters (highest log(BF10)log(BF_{10}) = -1.26). Dividing controls individuals aphantasia within cluster B two “sub-clusters” provided insights profiles sample (see Figure 4, right panel; details 60 pairwise comparisons can found extended analysis report OSF https://osf.io/7vsx6/). allowed assess imagery differences might biased averaging imagery scores mixed cluster. First, comparisons controls B (noted BCB_{C}) C showed C higher visual imagery BCB_{C} (log(BF10)log(BF_{10}) = 6.96), comparable sensory imagery (log(BF10)log(BF_{10}) = -0.78) auditory imagery scores (log(BF10)log(BF_{10}) = -2.36). observed , B-Controls higher spatial imagery (log(BF10)log(BF_{10}) = 9.56), spatial span (log(BF10)log(BF_{10}) = 1.53) verbal reasoning scores (log(BF10)log(BF_{10}) = 0.76), differences verbal strategies (log(BF10)log(BF_{10}) = -3.31) Raven + Digit span (log(BF10)log(BF_{10}) = -3.35). comparisons show main imagery differences B C controls lie visual spatial imagery, indicating differences performance observed tasks related balance two, high visual imagery associated lower performance. Last, comparisons individuals aphantasia B (noted BAB_{}) confirmed differences verbal strategies favour (log(BF10)log(BF_{10}) = 3.79), spatial imagery favour BAB_{} (log(BF10)log(BF_{10}) = 1.16), along absence differences Raven + Digit span (log(BF10)log(BF_{10}) = -0.88), spatial span (log(BF10)log(BF_{10}) = -2.02), verbal reasoning (log(BF10)log(BF_{10}) = -1.18). However, contrasts also revealed , although two comparable visual imagery (log(BF10)log(BF_{10}) = -4.02), BAB_{} higher sensory imagery (log(BF10)log(BF_{10}) = 2.46). difference also existed auditory imagery (log(BF10)log(BF_{10}) = 1.35), used variable clustering. differences verbal strategies, spatial imagery, sensory auditory imagery BAB_{} aphants point existence aphantasia subgroups major mental imagery cognitive style differences extending beyond visual imagery.","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/articles/manuscript.html","id":"vviq-groups-analysis","dir":"Articles","previous_headings":"","what":"VVIQ groups analysis","title":"Reproducible manuscript","text":"Participants’ level education, field study, occupation analysed detect association grouping factor. Levels education coded using equivalent French levels International Standard Classification Education (ISCED), .e., Upper secondary, Post-secondary, Bachelor, Master, Doctorate. Fields study coded according 10 broad categories defined ISCED-F 2013 (ISCED: Fields Education Training). Occupations coded according sub-major groups International Standard Classification Occupations (ISCO-08) appropriate level precision given sample size. Nine occupational groups identified sample. Bayes factors independence calculated evaluate association groups demographic variable (see Gûnel & Dickey, 1974). tests found evidence relationship groups levels education (log(BF10)log(BF_{10}) = -4.88), groups fields study (log(BF10)log(BF_{10}) = -5.41), groups occupation (log(BF10)log(BF_{10}) = -4.37). measured variables scores VVIQ, three OSIVQ scales, seven Psi-Q scales, Raven matrices, SRI, Similarities Test, reverse spatial verbal spans, WCST Reading comprehension task. Linear models fitted various variables model participant groups categorical predictors age continuous covariate control potential influence latter. Contrast analyses thereafter conducted assess differences groups. score differences (hereinafter referred Δ\\Delta) 95% Credible Intervals reported Table 1 along log(BF10)log(BF_{10}) quantifying weight evidence favour non-null difference groups. Individuals aphantasia lower scores controls visual imagery scales (VVIQ: log(BF10)log(BF_{10}) = 64.33; OSIVQ-Object: log(BF10)log(BF_{10}) = 37.94; Psi-Q Visual: log(BF10)log(BF_{10}) = 58.94), also sensory imaging modalities evaluated Psi-Q (log(BF10)∈[14;31]log(BF_{10}) \\[14; 31] modalities). means contrasts groups represented distributions Figure 1. Apart sensory imagery, evidence found favour difference groups verbal scale OSIVQ, individuals aphantasia scoring higher controls (Δ\\Delta = -6.39, 95% CrI = [-10.12, -2.53], log(BF10)log(BF_{10}) = 1.63). differences groups found variables: statistical analyses showed evidence difference spatial scale OSIVQ (log(BF10)log(BF_{10}) = -0.7), differences Raven matrices scores (log(BF10)log(BF_{10}) = -1.3), SRI scores (log(BF10)log(BF_{10}) = -2.2), spatial span (log(BF10)log(BF_{10}) = -1.01), digit span (log(BF10)log(BF_{10}) = -3.28), Similarities test scores (log(BF10)log(BF_{10}) = -2.68), Reading comprehension scores (log(BF10)log(BF_{10}) = -1.94) WCST scores (log(BF10)log(BF_{10}) = -3.22). Figure 1: Standardised scores two VVIQ groups questionnaires tasks. scores rescaled 0 1 represented scale. coloured shapes represent distribution scores group. coloured dots represent mean group, bars represent standard deviations. stars represent weight evidence thresholds favour effect Group: * = ‘Substantial evidence’, ** = ‘Strong evidence’, *** = ‘Decisive evidence’. VVIQ model—.e., division sample two VVIQ groups individuals aphantasia controls—therefore little explanatory power task performance. However, large inter-individual variances observed various outcomes, evidenced spread outcomes’ distributions several bimodal distributions (e.g., distributions OSIVQ-Verbal, SRI, Reading comprehension scores, see Figure 1). unexplained differences suggested existence underlying structure sample, thus requiring better model relevant groups account light data. studied hypothesis searching sub-groups sample using data-driven unsupervised clustering.","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/articles/manuscript.html","id":"education-and-occupation","dir":"Articles","previous_headings":"3 Results","what":"Education and occupation","title":"Reproducible manuscript","text":"Participants’ level education, field study, occupation analysed detect association grouping factor. Levels education coded using equivalent French levels International Standard Classification Education (ISCED), .e., Upper secondary, Post-secondary, Bachelor, Master, Doctorate. Fields study coded according 10 broad categories defined ISCED-F 2013 (ISCED: Fields Education Training). Occupations coded according sub-major groups International Standard Classification Occupations (ISCO-08) appropriate level precision given sample size. Nine occupational groups identified sample. Bayes factors independence calculated evaluate association groups demographic variable (see Gûnel & Dickey, 1974). tests found evidence relationship groups levels education (log(BF10)log(BF_{10}) = -4.88), groups fields study (log(BF10)log(BF_{10}) = -5.41), groups occupation (log(BF10)log(BF_{10}) = -4.37).","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/articles/manuscript.html","id":"questionnaire-and-task-results","dir":"Articles","previous_headings":"3 Results","what":"Questionnaire and task results","title":"Reproducible manuscript","text":"measured variables scores VVIQ, three OSIVQ scales, seven Psi-Q scales, Raven matrices, SRI, Similarities Test, reverse spatial verbal spans, WCST Reading comprehension task. Linear models fitted various variables model participant groups categorical predictors age continuous covariate control potential influence latter. Contrast analyses thereafter conducted assess differences groups. score differences (hereinafter referred Δ\\Delta) 95% Credible Intervals reported Table 1 along log(BF10)log(BF_{10}) quantifying weight evidence favour non-null difference groups. Individuals aphantasia lower scores controls visual imagery scales (VVIQ: log(BF10)log(BF_{10}) = 64.33; OSIVQ-Object: log(BF10)log(BF_{10}) = 37.94; Psi-Q Visual: log(BF10)log(BF_{10}) = 58.94), also sensory imaging modalities evaluated Psi-Q (log(BF10)∈[14;31]log(BF_{10}) \\[14; 31] modalities). means contrasts groups represented distributions Figure 1. Apart sensory imagery, evidence found favour difference groups verbal scale OSIVQ, individuals aphantasia scoring higher controls (Δ\\Delta = -6.39, 95% CrI = [-10.12, -2.53], log(BF10)log(BF_{10}) = 1.63). differences groups found variables: statistical analyses showed evidence difference spatial scale OSIVQ (log(BF10)log(BF_{10}) = -0.7), differences Raven matrices scores (log(BF10)log(BF_{10}) = -1.3), SRI scores (log(BF10)log(BF_{10}) = -2.2), spatial span (log(BF10)log(BF_{10}) = -1.01), digit span (log(BF10)log(BF_{10}) = -3.28), Similarities test scores (log(BF10)log(BF_{10}) = -2.68), Reading comprehension scores (log(BF10)log(BF_{10}) = -1.94) WCST scores (log(BF10)log(BF_{10}) = -3.22). Figure 1: Standardised scores two VVIQ groups questionnaires tasks. scores rescaled 0 1 represented scale. coloured shapes represent distribution scores group. coloured dots represent mean group, bars represent standard deviations. stars represent weight evidence thresholds favour effect Group: * = ‘Substantial evidence’, ** = ‘Strong evidence’, *** = ‘Decisive evidence’. VVIQ model—.e., division sample two VVIQ groups individuals aphantasia controls—therefore little explanatory power task performance. However, large inter-individual variances observed various outcomes, evidenced spread outcomes’ distributions several bimodal distributions (e.g., distributions OSIVQ-Verbal, SRI, Reading comprehension scores, see Figure 1). unexplained differences suggested existence underlying structure sample, thus requiring better model relevant groups account light data. studied hypothesis searching sub-groups sample using data-driven unsupervised clustering.","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/articles/manuscript.html","id":"cluster-analysis","dir":"Articles","previous_headings":"","what":"Cluster analysis","title":"Reproducible manuscript","text":"selection relevant variables clustering essential good model fit interpretation results (Fop & Murphy, 2018; Zakharov, 2016). adequate number dimensions (variables) given sample size also crucial increase quality clustering (Psutka & Psutka, 2019). identification reduction redundant variables particularly important, distort relative weight latent variable clustering process. two variables represent concept, concept represented twice data hence get twice weight variables. final solution skewed direction concept, considerably compromise relevance model understanding variable importance (Kyriazos & Poga, 2023). present analysis, issue particularly affected sensory imagery, represented nine highly correlated variables (VVIQ, OSIVQ-Object, seven Psi-Q modalities, Pearson’s r∈[0.65,0.94]r \\[0.65, 0.94] every pairwise correlation) likely reflect similar constructs, opposed remaining nine variables. Several methods exist deal multicollinearity problems. low-dimensional setting, chose merge variables averaging maintain interpretability enhancing stability model (Kyriazos & Poga, 2023). choose variables merge, analysed relationships variables using partial correlations. Partial correlations measure degree association two variables controlling effect potentially confounding covariates (Abdi, 2007). procedure allows identify strongest unbiased links variables prevents misinterpretation spurious correlations. computed partial correlations 18 variables (see Figure 2) chose merge significantly correlated variables Bonferroni correction (multiplying p-values number comparisons). resulted creation four new reduced variables. First, three subscales related visual imagery, .e., VVIQ, OSIVQ-Object Psi-Q Visual, associated (VVIQ - Psi-Q Visual: r = 0.67, p << 0.001; OSIVQ-Object - Psi-Q Visual: r = 0.36, p << 0.05). standardised 0 1, weighted number items (16, 15 3 respectively) merged single “Visual imagery” variable obtain balanced continuous measure imagery possible. Second, OSIVQ-Spatial score SRI, .e., subjective objective spatial imagery, associated (r = 0.36, p << 0.05). standardised merged single “Spatial imagery” variable. Third, five Psi-Q sensory imagery subscales (Smell, Taste, Touch, Sensations Feelings) associated (Psi-Q Smell - Taste: r = 0.47, p << 0.001; Taste - Touch: r = 0.38, p << 0.05; Touch - Sensations: r = 0.41, p << 0.01; Sensations - Feelings: r = 0.39, p << 0.05). standardised merged single “Sensory imagery” variable. Fourth, score Raven matrices Digit span associated (r = 0.37, p << 0.05). standardised merged common “Raven + Digit” variable. Based link established reverse digit span measures intellectual executive functions (Groeger et al., 1999), interpreted variable theoretically proxy general cognitive performance. Figure 2: Correlation matrix undirected graph representing partial correlations 18 variables. stars matrix represent p-value thresholds: * : p << 0.05, ** : p << 0.01, *** : p << 0.001, Bonferroni correction. links graph represent significant partial correlations. coloured (non-black) nodes highlight variables used clustering, result merging several correlated variables. Light blue: Visual imagery; dark blue: Sensory imagery; light orange: Spatial imagery; green: Verbal strategies; pink: Raven + Digit; dark orange: Verbal reasoning. Finally, three variables included clustering. Psi-Q Auditory Psi-Q subscale associated variables. comprises three items, variable included clustering avoid giving undue importance. WCST Reading comprehension scores used either, tasks designed evaluate higher-level abilities operate integrated levels cognition. Executive functioning reading comprehension inextricably involve mix working memory, reasoning attention (Heaton & Staff, 1993; Kongs et al., 2000; Suggate & Lenhard, 2022), likely integrate many redundant processes assessments. Instead, variables used posteriori testing variables assess generalisability cluster model external variables, .e., related sensory imagery subscale Psi-Q Auditory, complex cognitive tasks two. decision planned study, decided conducting cluster analysis based variable reduction theoretical considerations. entire selection procedure allowed reduce variable space seven dimensions, estimated Psutka & Psutka (2019) yield good accuracy parameter recovery model-based clustering (see next section) sample N = 96. result, variables modified keep much information possible. sake clarity, several scores renamed reflect assess. OSIVQ-Verbal score identified propensity use Verbal strategies information processing, line definition sub-scale (see Blazhenkova & Kozhevnikov, 2009). Similarities test score identified Verbal Reasoning variable. clustering process therefore conducted seven following variables: Visual imagery, Sensory imagery, Spatial imagery, Verbal strategies, Raven + Digit span, Verbal reasoning Spatial span. model variables using scale, data normalized 0 1 respective scales, recommended Zakharov (2016). model-based method chosen clustering. approach, clustering aims modelling distributions mixtures multivariate Gaussian distributions (Steinley & Brusco, 2011). Finite Gaussian mixture models (GMM) attempt determine underlying population groups produced observed data, cluster distribution centre spread. resulting model used compute probability observation belonging cluster. Although discrete (k-means) hierarchical clustering methods frequently used psychology (Zakharov, 2016), probabilistic mixture modelling approaches proven powerful parsimonious partially overlapping, non-spherical, multivariate normal distributions, small sample sizes, common psychology experiments (Dalmaijer et al., 2022). Given little information available clusters, estimation GMM proceeds steps, alternating (1) estimating posterior probability observation belonging cluster fixed set parameters (2) updating estimates parameters fixing probability cluster membership observation (Steinley & Brusco, 2011). iterative procedure continues model converges stable clusters. standard method estimation expectation-maximisation algorithm (EM, Dempster et al., 1977)1. present study, mclust R package (Scrucca et al., 2023) used conduct GMM clustering. estimation procedure mixture clusters GMM requires knowledge number clusters distributional form. determination parameters done using Bayesian Information Criterion (BIC) implemented mclust package. Figure 3: Comparison goodness fit different mixture models used clustering function model type number components. high BIC indicates good model fit. three-letter acronyms describe components mixture models. first letter describes volume components, second shape last orientation. E = equal, V = variable. Acronyms ending ‘II’ indicate mixtures spherical components, ending ‘’ indicate mixtures diagonal components without ‘’ indicate mixtures ellipsoidal components. generally accepted rules regarding minimum sample sizes clustering procedures. model-based clustering procedures Dalmaijer et al. (2022) recommended N = 20 N = 30 per expected cluster medium large effect sizes (.e., cluster separation), translate two four clusters sample. Given present dataset, comparison various GMM types different number clusters using BIC showed best solution model three ellipsoidal clusters varying shapes, equal volume orientations (EVE model, see Figure 3). profiles three clusters obtained presented Figure 4 (left panel). Cluster made exclusively individuals aphantasia (NAN_A = 32), Cluster B mixed (NBN_B = 30), comprising 17 controls 13 individuals aphantasia, Cluster C composed solely control participants (NCN_C = 34). Bayes factors independence found association clusters levels education (log(BF10)log(BF_{10}) = -7.44), clusters fields study (log(BF10)log(BF_{10}) = -6.06), clusters occupation (log(BF10)log(BF_{10}) = -3.88). Figure 4: Profiles clusters obtained model-based clustering. Left: Polar plot representing standardised means (points) standard errors (error bars) three clusters seven clustering variables three external variables (Auditory imagery, WCST Reading comprehension). Cluster exclusively composed individuals aphantasia, Cluster C exclusively composed control participants, Cluster B mixed. Right: polar plot Cluster B divided two sub-clusters, ‘B-Aphant.’ 13 individuals aphantasia B, ‘B-Control’ 17 control participants B. Cluster scores modelled clusters predictors using linear Bayesian modelling described modelling variables groups. detailed pairwise differences clusters 95% Credible Intervals reported Table 2 along weights evidence favour differences clusters. three clusters distinctive features visual, sensory, spatial verbal dimensions cognitive profiles. seen, Visual Sensory imagery, Controls (cluster C) much higher scores mixed cluster (cluster B) higher scores Aphantasic cluster (cluster ; log(BF10)≥log(BF_{10}) \\geq 3.99). Cluster B higher scores two clusters Spatial imagery (log(BF10)≥log(BF_{10}) \\geq 5.52), differ (log(BF10)log(BF_{10}) = -1.74). turn, cluster higher scores two Verbal strategies (log(BF10)≥log(BF_{10}) \\geq 4.31), B C differ (log(BF10)log(BF_{10}) = -3.19). Else, cluster B outperformed cluster C verbal reasoning spatial span (log(BF10)≥log(BF_{10}) \\geq 3.33), differences found cluster two scores (log(BF10)≤log(BF_{10}) \\leq 0.16). Finally, Raven + Digit span variable, differences clusters negligible (log(BF10)≤log(BF_{10}) \\leq -2.2). also modelled variables excluded clustering procedure, .e., Auditory imagery, WCST reading comprehension scores, assess cluster patterns transferred external variables. seen bottom Table 2. imagery patterns maintained Auditory imagery, cluster C scored higher B (log(BF10)log(BF_{10}) = 2.33), turn scored higher (log(BF10)log(BF_{10}) = 11.37). However, although mean cluster scores WCST reading comprehension followed trend cognitive tasks (.e. B >> >> C — WCST: MBM_{B} (SDBSD_{B}) = 0.66 (0.14); MAM_{} (SDASD_{}) = 0.65 (0.13); MCM_{C} (SDCSD_{C}) = 0.6 (0.16) — Reading comprehension: MBM_{B} (SDBSD_{B}) = 0.63 (0.2); MAM_{} (SDASD_{}) = 0.6 (0.16); MCM_{C} (SDCSD_{C}) = 0.52 (0.23)), evidence absence differences clusters (highest log(BF10)log(BF_{10}) = -1.26). Dividing controls individuals aphantasia within cluster B two “sub-clusters” provided insights profiles sample (see Figure 4, right panel; details 60 pairwise comparisons can found extended analysis report OSF https://osf.io/7vsx6/). allowed assess imagery differences might biased averaging imagery scores mixed cluster. First, comparisons controls B (noted BCB_{C}) C showed C higher visual imagery BCB_{C} (log(BF10)log(BF_{10}) = 6.96), comparable sensory imagery (log(BF10)log(BF_{10}) = -0.78) auditory imagery scores (log(BF10)log(BF_{10}) = -2.36). observed , B-Controls higher spatial imagery (log(BF10)log(BF_{10}) = 9.56), spatial span (log(BF10)log(BF_{10}) = 1.53) verbal reasoning scores (log(BF10)log(BF_{10}) = 0.76), differences verbal strategies (log(BF10)log(BF_{10}) = -3.31) Raven + Digit span (log(BF10)log(BF_{10}) = -3.35). comparisons show main imagery differences B C controls lie visual spatial imagery, indicating differences performance observed tasks related balance two, high visual imagery associated lower performance. Last, comparisons individuals aphantasia B (noted BAB_{}) confirmed differences verbal strategies favour (log(BF10)log(BF_{10}) = 3.79), spatial imagery favour BAB_{} (log(BF10)log(BF_{10}) = 1.16), along absence differences Raven + Digit span (log(BF10)log(BF_{10}) = -0.88), spatial span (log(BF10)log(BF_{10}) = -2.02), verbal reasoning (log(BF10)log(BF_{10}) = -1.18). However, contrasts also revealed , although two comparable visual imagery (log(BF10)log(BF_{10}) = -4.02), BAB_{} higher sensory imagery (log(BF10)log(BF_{10}) = 2.46). difference also existed auditory imagery (log(BF10)log(BF_{10}) = 1.35), used variable clustering. differences verbal strategies, spatial imagery, sensory auditory imagery BAB_{} aphants point existence aphantasia subgroups major mental imagery cognitive style differences extending beyond visual imagery.","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/articles/manuscript.html","id":"correlation-structure-and-variable-selection","dir":"Articles","previous_headings":"3 Results","what":"Correlation structure and variable selection","title":"Reproducible manuscript","text":"selection relevant variables clustering essential good model fit interpretation results (Fop & Murphy, 2018; Zakharov, 2016). adequate number dimensions (variables) given sample size also crucial increase quality clustering (Psutka & Psutka, 2019). identification reduction redundant variables particularly important, distort relative weight latent variable clustering process. two variables represent concept, concept represented twice data hence get twice weight variables. final solution skewed direction concept, considerably compromise relevance model understanding variable importance (Kyriazos & Poga, 2023). present analysis, issue particularly affected sensory imagery, represented nine highly correlated variables (VVIQ, OSIVQ-Object, seven Psi-Q modalities, Pearson’s r∈[0.65,0.94]r \\[0.65, 0.94] every pairwise correlation) likely reflect similar constructs, opposed remaining nine variables. Several methods exist deal multicollinearity problems. low-dimensional setting, chose merge variables averaging maintain interpretability enhancing stability model (Kyriazos & Poga, 2023). choose variables merge, analysed relationships variables using partial correlations. Partial correlations measure degree association two variables controlling effect potentially confounding covariates (Abdi, 2007). procedure allows identify strongest unbiased links variables prevents misinterpretation spurious correlations. computed partial correlations 18 variables (see Figure 2) chose merge significantly correlated variables Bonferroni correction (multiplying p-values number comparisons). resulted creation four new reduced variables. First, three subscales related visual imagery, .e., VVIQ, OSIVQ-Object Psi-Q Visual, associated (VVIQ - Psi-Q Visual: r = 0.67, p << 0.001; OSIVQ-Object - Psi-Q Visual: r = 0.36, p << 0.05). standardised 0 1, weighted number items (16, 15 3 respectively) merged single “Visual imagery” variable obtain balanced continuous measure imagery possible. Second, OSIVQ-Spatial score SRI, .e., subjective objective spatial imagery, associated (r = 0.36, p << 0.05). standardised merged single “Spatial imagery” variable. Third, five Psi-Q sensory imagery subscales (Smell, Taste, Touch, Sensations Feelings) associated (Psi-Q Smell - Taste: r = 0.47, p << 0.001; Taste - Touch: r = 0.38, p << 0.05; Touch - Sensations: r = 0.41, p << 0.01; Sensations - Feelings: r = 0.39, p << 0.05). standardised merged single “Sensory imagery” variable. Fourth, score Raven matrices Digit span associated (r = 0.37, p << 0.05). standardised merged common “Raven + Digit” variable. Based link established reverse digit span measures intellectual executive functions (Groeger et al., 1999), interpreted variable theoretically proxy general cognitive performance. Figure 2: Correlation matrix undirected graph representing partial correlations 18 variables. stars matrix represent p-value thresholds: * : p << 0.05, ** : p << 0.01, *** : p << 0.001, Bonferroni correction. links graph represent significant partial correlations. coloured (non-black) nodes highlight variables used clustering, result merging several correlated variables. Light blue: Visual imagery; dark blue: Sensory imagery; light orange: Spatial imagery; green: Verbal strategies; pink: Raven + Digit; dark orange: Verbal reasoning. Finally, three variables included clustering. Psi-Q Auditory Psi-Q subscale associated variables. comprises three items, variable included clustering avoid giving undue importance. WCST Reading comprehension scores used either, tasks designed evaluate higher-level abilities operate integrated levels cognition. Executive functioning reading comprehension inextricably involve mix working memory, reasoning attention (Heaton & Staff, 1993; Kongs et al., 2000; Suggate & Lenhard, 2022), likely integrate many redundant processes assessments. Instead, variables used posteriori testing variables assess generalisability cluster model external variables, .e., related sensory imagery subscale Psi-Q Auditory, complex cognitive tasks two. decision planned study, decided conducting cluster analysis based variable reduction theoretical considerations. entire selection procedure allowed reduce variable space seven dimensions, estimated Psutka & Psutka (2019) yield good accuracy parameter recovery model-based clustering (see next section) sample N = 96. result, variables modified keep much information possible. sake clarity, several scores renamed reflect assess. OSIVQ-Verbal score identified propensity use Verbal strategies information processing, line definition sub-scale (see Blazhenkova & Kozhevnikov, 2009). Similarities test score identified Verbal Reasoning variable. clustering process therefore conducted seven following variables: Visual imagery, Sensory imagery, Spatial imagery, Verbal strategies, Raven + Digit span, Verbal reasoning Spatial span. model variables using scale, data normalized 0 1 respective scales, recommended Zakharov (2016).","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/articles/manuscript.html","id":"model-based-clustering-and-number-of-clusters","dir":"Articles","previous_headings":"3 Results","what":"Model-based clustering and number of clusters","title":"Reproducible manuscript","text":"model-based method chosen clustering. approach, clustering aims modelling distributions mixtures multivariate Gaussian distributions (Steinley & Brusco, 2011). Finite Gaussian mixture models (GMM) attempt determine underlying population groups produced observed data, cluster distribution centre spread. resulting model used compute probability observation belonging cluster. Although discrete (k-means) hierarchical clustering methods frequently used psychology (Zakharov, 2016), probabilistic mixture modelling approaches proven powerful parsimonious partially overlapping, non-spherical, multivariate normal distributions, small sample sizes, common psychology experiments (Dalmaijer et al., 2022). Given little information available clusters, estimation GMM proceeds steps, alternating (1) estimating posterior probability observation belonging cluster fixed set parameters (2) updating estimates parameters fixing probability cluster membership observation (Steinley & Brusco, 2011). iterative procedure continues model converges stable clusters. standard method estimation expectation-maximisation algorithm (EM, Dempster et al., 1977)1. present study, mclust R package (Scrucca et al., 2023) used conduct GMM clustering. estimation procedure mixture clusters GMM requires knowledge number clusters distributional form. determination parameters done using Bayesian Information Criterion (BIC) implemented mclust package. Figure 3: Comparison goodness fit different mixture models used clustering function model type number components. high BIC indicates good model fit. three-letter acronyms describe components mixture models. first letter describes volume components, second shape last orientation. E = equal, V = variable. Acronyms ending ‘II’ indicate mixtures spherical components, ending ‘’ indicate mixtures diagonal components without ‘’ indicate mixtures ellipsoidal components. generally accepted rules regarding minimum sample sizes clustering procedures. model-based clustering procedures Dalmaijer et al. (2022) recommended N = 20 N = 30 per expected cluster medium large effect sizes (.e., cluster separation), translate two four clusters sample. Given present dataset, comparison various GMM types different number clusters using BIC showed best solution model three ellipsoidal clusters varying shapes, equal volume orientations (EVE model, see Figure 3).","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/articles/manuscript.html","id":"clustering-results","dir":"Articles","previous_headings":"3 Results","what":"Clustering results","title":"Reproducible manuscript","text":"profiles three clusters obtained presented Figure 4 (left panel). Cluster made exclusively individuals aphantasia (NAN_A = 32), Cluster B mixed (NBN_B = 30), comprising 17 controls 13 individuals aphantasia, Cluster C composed solely control participants (NCN_C = 34). Bayes factors independence found association clusters levels education (log(BF10)log(BF_{10}) = -7.44), clusters fields study (log(BF10)log(BF_{10}) = -6.06), clusters occupation (log(BF10)log(BF_{10}) = -3.88). Figure 4: Profiles clusters obtained model-based clustering. Left: Polar plot representing standardised means (points) standard errors (error bars) three clusters seven clustering variables three external variables (Auditory imagery, WCST Reading comprehension). Cluster exclusively composed individuals aphantasia, Cluster C exclusively composed control participants, Cluster B mixed. Right: polar plot Cluster B divided two sub-clusters, ‘B-Aphant.’ 13 individuals aphantasia B, ‘B-Control’ 17 control participants B. Cluster scores modelled clusters predictors using linear Bayesian modelling described modelling variables groups. detailed pairwise differences clusters 95% Credible Intervals reported Table 2 along weights evidence favour differences clusters. three clusters distinctive features visual, sensory, spatial verbal dimensions cognitive profiles. seen, Visual Sensory imagery, Controls (cluster C) much higher scores mixed cluster (cluster B) higher scores Aphantasic cluster (cluster ; log(BF10)≥log(BF_{10}) \\geq 3.99). Cluster B higher scores two clusters Spatial imagery (log(BF10)≥log(BF_{10}) \\geq 5.52), differ (log(BF10)log(BF_{10}) = -1.74). turn, cluster higher scores two Verbal strategies (log(BF10)≥log(BF_{10}) \\geq 4.31), B C differ (log(BF10)log(BF_{10}) = -3.19). Else, cluster B outperformed cluster C verbal reasoning spatial span (log(BF10)≥log(BF_{10}) \\geq 3.33), differences found cluster two scores (log(BF10)≤log(BF_{10}) \\leq 0.16). Finally, Raven + Digit span variable, differences clusters negligible (log(BF10)≤log(BF_{10}) \\leq -2.2). also modelled variables excluded clustering procedure, .e., Auditory imagery, WCST reading comprehension scores, assess cluster patterns transferred external variables. seen bottom Table 2. imagery patterns maintained Auditory imagery, cluster C scored higher B (log(BF10)log(BF_{10}) = 2.33), turn scored higher (log(BF10)log(BF_{10}) = 11.37). However, although mean cluster scores WCST reading comprehension followed trend cognitive tasks (.e. B >> >> C — WCST: MBM_{B} (SDBSD_{B}) = 0.66 (0.14); MAM_{} (SDASD_{}) = 0.65 (0.13); MCM_{C} (SDCSD_{C}) = 0.6 (0.16) — Reading comprehension: MBM_{B} (SDBSD_{B}) = 0.63 (0.2); MAM_{} (SDASD_{}) = 0.6 (0.16); MCM_{C} (SDCSD_{C}) = 0.52 (0.23)), evidence absence differences clusters (highest log(BF10)log(BF_{10}) = -1.26). Dividing controls individuals aphantasia within cluster B two “sub-clusters” provided insights profiles sample (see Figure 4, right panel; details 60 pairwise comparisons can found extended analysis report OSF https://osf.io/7vsx6/). allowed assess imagery differences might biased averaging imagery scores mixed cluster. First, comparisons controls B (noted BCB_{C}) C showed C higher visual imagery BCB_{C} (log(BF10)log(BF_{10}) = 6.96), comparable sensory imagery (log(BF10)log(BF_{10}) = -0.78) auditory imagery scores (log(BF10)log(BF_{10}) = -2.36). observed , B-Controls higher spatial imagery (log(BF10)log(BF_{10}) = 9.56), spatial span (log(BF10)log(BF_{10}) = 1.53) verbal reasoning scores (log(BF10)log(BF_{10}) = 0.76), differences verbal strategies (log(BF10)log(BF_{10}) = -3.31) Raven + Digit span (log(BF10)log(BF_{10}) = -3.35). comparisons show main imagery differences B C controls lie visual spatial imagery, indicating differences performance observed tasks related balance two, high visual imagery associated lower performance. Last, comparisons individuals aphantasia B (noted BAB_{}) confirmed differences verbal strategies favour (log(BF10)log(BF_{10}) = 3.79), spatial imagery favour BAB_{} (log(BF10)log(BF_{10}) = 1.16), along absence differences Raven + Digit span (log(BF10)log(BF_{10}) = -0.88), spatial span (log(BF10)log(BF_{10}) = -2.02), verbal reasoning (log(BF10)log(BF_{10}) = -1.18). However, contrasts also revealed , although two comparable visual imagery (log(BF10)log(BF_{10}) = -4.02), BAB_{} higher sensory imagery (log(BF10)log(BF_{10}) = 2.46). difference also existed auditory imagery (log(BF10)log(BF_{10}) = 1.35), used variable clustering. differences verbal strategies, spatial imagery, sensory auditory imagery BAB_{} aphants point existence aphantasia subgroups major mental imagery cognitive style differences extending beyond visual imagery.","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/articles/manuscript.html","id":"discussion","dir":"Articles","previous_headings":"","what":"Discussion","title":"Reproducible manuscript","text":"present study investigated cognitive profiles individuals without aphantasia profiles influence performance various cognitive tasks. end, examined key aspects subjective experiences, including visual sensory imagery, spatial imagery, verbal strategies, using questionnaires. Additionally, reasoning, working memory, executive functioning, reading comprehension assessed battery behavioural tasks. initial analyses, comparing individuals aphantasia controls based conventional measures, revealed significant differences performance. individuals aphantasia demonstrated reduced sensory imagery stronger reliance verbal strategies, differences spatial imagery cognitive tasks, reasoning memory, minimal. findings aligned previous research emphasizing limited impact aphantasia many behavioural tasks (e.g., Bainbridge et al., 2021; Keogh et al., 2021; Knight et al., 2022; Pounder et al., 2022). However, clustering analysis using Gaussian Mixture Model (GMM) identified cluster structure within dataset. leveraging variables related visual, sensory, spatial imagery, verbal strategies, cognitive abilities (.e., Raven matrices, digit span, spatial span, verbal reasoning), algorithm suggested presence three distinct cognitive profiles, unique characteristics visual, sensory, spatial imagery, well verbal strategies. One cluster, exclusively composed controls, demonstrated high visual sensory imagery, strongly relying visual-object representations. Another mixed cluster, including individuals aphantasia controls, exhibited strong spatial imagery performed best spatial span verbal reasoning tasks. final cluster consisted entirely individuals aphantasia, displayed multisensory aphantasia (reduced sensory, auditory, visual imagery) reliance verbal strategies. clustering revealed complex, multidimensional patterns cognitive abilities imagery preferences extended beyond binary categorization aphantasia versus control, offering rich nuanced picture relationships mental imagery cognition. focus Control participants, cluster analyses revealed important subgroup distinctions. Controls divided two subgroups: one highly vivid visual imagery reduced spatial imagery (cluster C) another opposite pattern, characterized stronger spatial imagery (cluster BCB_{C}). distinctions held important implications task performance. Individuals higher spatial imagery outperformed counterparts stronger visual imagery tasks requiring reasoning working memory, spatial span verbal reasoning tasks. Interestingly, groups performed similarly tasks involving non-verbal reasoning (Raven matrices) reverse digit span, suggesting observed differences due overall disparities cognitive ability specific differences imagery style. results emphasize importance spatial imagery abstract reasoning suggest vivid visual imagery may sometimes impede processes. consistent “visual imagery impedance hypothesis” (Knauff & Johnson-Laird, 2002), posits overly detailed visual representations can disrupt reasoning introducing irrelevant information. findings reinforce relevance spatial imagery cognitive profiles also raise questions relationship visual imagery, highlighting potential trade-offs visual spatial imagery capacities, dynamic previously suggested Kozhevnikov et al. (2010). clustering approach also revealed important heterogeneity within group individuals aphantasia. shared absence visual imagery defined participants aphantasia, two distinct subgroups emerged: one relied heavily spatial strategies (“spatialisers”) another depended predominantly verbal processing (“verbalisers”). Spatialisers demonstrated preserved sensory auditory imagery demonstrated strong performance tasks emphasized spatial representation, mental rotation spatial manipulation tasks. Verbalisers, contrast, exhibited described “multisensory aphantasia” reporting absence visual imagery also reduced absent sensory auditory imagery. group relied heavily verbal strategies, preference linguistic forms information processing. distinction “multisensory aphantasia” “visual-aphantasia” aligns prior clustering study conducted Dawes et al. (2023), highlighted heterogeneity aphantasia across larger samples. However, findings show another relevant dimension linking aphantasia profiles different cognitive styles: verbal versus spatial. strong performance spatialisers spatial tasks supports prior work suggesting many classic “mental imagery tasks”, Mental Rotation Task (Shepard & Metzler, 1971), Paper Folding Test (Ekstrom, 1976) rely heavily spatial visual-object imagery (Blazhenkova & Kozhevnikov, 2009; Bled & Bouvet, 2021; Borst & Kosslyn, 2010; Haciomeroglu, 2016; e.g., Kozhevnikov et al., 2005; Kozhevnikov et al., 2010). Furthermore, findings cognitive styles provide insights individuals aphantasia perform well spatial reasoning tasks, echoing earlier work amodal nature spatial representations (Johnson-Laird, 2010) spatial imagery aphantasia (Palermo et al., 2022). Nuances spatial imagery cognitive styles among individuals aphantasia may also related presence absence unconscious visual representations, phenomenon currently debated literature (see Krempel & Monzel, 2024; Muraki et al., 2023; Purkart et al., 2024). respect, unsupervised clustering unveil previously unrecognised heterogeneities within visual imagery groups, offering novel insights cognitive architectures underlying mental representations. spatial verbal profiles observed aphantasia profiles also broader implications beyond cognitive processes task performance. Zeman et al. (2020) noted disproportionate representation individuals aphantasia STEM fields, may reflect influence spatial profiles among individuals visual aphantasia. Indeed, numerous studies associations OSIVQ categories occupation, study activity found correlations three visual-object, spatial verbal dimensions areas specialisation visual arts, science humanities, respectively (extended review, see Blazhenkova & Pechenkova, 2019). patterns suggest cognitive profiles encompassing spatial verbal dimensions relevant understand consequences aphantasia ecological contexts, supported recent findings linking OSIVQ-derived profiles real-world problem-solving abilities (Chkhaidze et al., 2023; Höffler et al., 2017). Aphantasia may represent one extreme among many larger, multidimensional cognitive spectrum, individual differences imagery cognitive style influence cognitive abilities, subjective experience daily life. Since first systematic investigation aphantasia (Zeman et al., 2015), individuals condition reported “compensatory strengths verbal, mathematical logical domains”, understanding cognitive strengths weaknesses associated aphantasia remains incomplete. profiles identified study offer potential framework explore compensatory mechanisms , several limitations must acknowledged. use unsupervised clustering algorithm allowed discovery hidden structures data, findings remain exploratory require replication larger, diverse samples. Although use trans-categorical approach (clustering mixed sample people aphantasia typical imagery) allowed us reveal relevant dimensions cognitive profiles, may nuanced patterns aphantasia study unable capture due sample size. Moreover, tasks used assess mental imagery reasoning selected provide broad coverage cognitive abilities may captured full complexity constructs. Future research aim refine measurement visual, spatial, verbal imagery use tasks specifically designed disentangle dimensions. instance, relation OSIVQ, Degraded Pictures Task (Blazhenkova & Kozhevnikov, 2009; Kozhevnikov et al., 2005; Kozhevnikov et al., 2010), Paper Folding Test (Blazhenkova & Kozhevnikov, 2009; Haciomeroglu, 2016; Höffler et al., 2017; Kozhevnikov et al., 2005) vocabulary tasks (Blazhenkova & Kozhevnikov, 2009; Bled & Bouvet, 2021) shown correlate object, spatial verbal scores, respectively. Furthermore, remains seen whether profiles identified can validated behavioural neural phenomena, differences brain activity visual spatial imagery tasks. Overall, findings study suggest variations visual, spatial, verbal cognitive styles offer rich framework understanding “phantasia continuum”. framework highlights heterogeneity within aphantasia population also situates aphantasia within broader spectrum cognitive abilities. Ultimately, moving beyond binary classification aphantasia exploring multidimensional nature cognitive profiles, study aims contribute nuanced cohesive understanding diversity mental imagery cognitive implications. turn, spectacular variability inner experiences represents invaluable source information mental representations, answer long-standing questions nature, modal amodal properties interaction fundamental processes reasoning, problem-solving working memory.","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/articles/manuscript.html","id":"research-transparency-statement","dir":"Articles","previous_headings":"","what":"Research transparency statement","title":"Reproducible manuscript","text":"following elements required reproduce study analyses publicly available Open Science Framework (https://osf.io/7vsx6/): online study materials; anonymised primary data pre-processed data; analysis code notebooks extensive commentary supplementary information exploratory analysis process results. artificial intelligence assisted technologies used research creation article.","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/articles/manuscript.html","id":"author-contributions","dir":"Articles","previous_headings":"","what":"Author contributions","title":"Reproducible manuscript","text":"Conceptualisation: MD, ST, EC, GP. Data curation: MD. Formal analysis: MD. Funding acquisition: GP. Investigation: MD, ST. Methodology: MD, ST, DC, EC, GP. Project administration: GP, EC. Resources: MD, ST, EC, DC. Software: MD. Supervision: GP, EC. Visualisation: MD. Writing - Original Draft Preparation: MD. Writing - Review & Editing: GP, DC, EC.","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/articles/manuscript.html","id":"declaration-of-interests","dir":"Articles","previous_headings":"","what":"Declaration of interests","title":"Reproducible manuscript","text":"None.","code":""},{"path":[]},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/articles/manuscript.html","id":"tables","dir":"Articles","previous_headings":"","what":"Tables","title":"Reproducible manuscript","text":"Table 1: Means standard deviations (SD) scores VVIQ group every variable. score differences, 95% Credible Intervals (CrI) weights evidence reported variable. Table 2: Pairwise comparisons three clusters seven clustering variables three external variables (Auditory imagery, WCST Reading comprehension). log(BF10)log(BF_{10}) quantifies weight evidence favour difference clusters.","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Maël Delem. Author, maintainer.","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Delem M (2025). aphantasiaCognitiveClustering: Data Analysis \"Unsupervised clustering reveals spatial verbal cognitive profiles aphantasia typical imagery\". R package version 1.0, https://m-delem.github.io/aphantasiaCognitiveClustering/.","code":"@Manual{,   title = {aphantasiaCognitiveClustering: Data Analysis for \"Unsupervised clustering reveals spatial and verbal cognitive profiles in aphantasia and typical imagery\"},   author = {Maël Delem},   year = {2025},   note = {R package version 1.0},   url = {https://m-delem.github.io/aphantasiaCognitiveClustering/}, }"},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/index.html","id":"aphantasiacognitiveclustering-","dir":"","previous_headings":"","what":"Data Analysis for ","title":"Data Analysis for ","text":"aphantasiaCognitiveClustering data analysis project wrapped R package reproducibility1. contains code data reproduce analyses presented article “Unsupervised clustering reveals spatial verbal cognitive profiles aphantasia typical imagery”. can read accepted manuscript free . study materials available Open Science Framework .","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/index.html","id":"what-exactly-is-in-this-r-package","dir":"","previous_headings":"","what":"What exactly is in this R package?","title":"Data Analysis for ","text":"package includes preprocessed data ready analysis form built-dataset called study_data make easily accessible. package comes set functions manipulating data reliably reproducing analyses presented article. data functions documented detail package website, also includes: data analysis report describing use package reproduce analyses reproducible version manuscript numerical results generated directly package rendered using Quarto. source code notebooks also available vignettes/ folder package repository.","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Data Analysis for ","text":"can install development version aphantasiaCognitiveClustering GitHub : Alternatively, can clone repository, launch R project RStudio opening aphantasiaCognitiveClustering.Rproj file run following command: … load package make functions data available R session.","code":"# install.packages(\"pak\") pak::pak(\"m-delem/aphantasiaCognitiveClustering\") devtools::load_all() #> ℹ Loading aphantasiaCognitiveClustering #> Welcome to aphantasiaCognitiveClustering. #> See https://osf.io/7vsx6/ for the associated study."},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/index.html","id":"examples","dir":"","previous_headings":"","what":"Examples","title":"Data Analysis for ","text":"examples use data functions package recreate graphs article. Score comparisons groups original variables:  Correlation matrix graph study variables:  Clustering radar plots clusters:  Visit package website detailed explanations package features!","code":"library(aphantasiaCognitiveClustering) study_data |>    scale_vars() |>    get_longer() |>   filter_study_variables(\"original\") |>    plot_score_violins() study_data |> correlate_vars(partial = TRUE) |> plot_score_cor_joint() library(patchwork)  df <-   merge_clusters(     df_raw = study_data,     df_red = scale_reduce_vars(study_data),     clustering = cluster_selected_vars(study_data)   ) |>   scale_vars() |>   get_longer() |>   filter_study_variables(\"reduced\")  plot_score_radars(df, Cluster, r_off = 6, l_off = 6) +    plot_score_radars(df, Subcluster, r_off = 6, l_off = 6)"},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/index.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Data Analysis for ","text":"GitHub repository archived  OSF project dedicated study, allowed assign permanent DOI code data. Thus, use code data research, please cite OSF project one following: Delem, M., Cousineau, D., Cavalli, E., & Plancher, G. (2025, November 19). Supplementary materials ‘Unsupervised clustering reveals cognitive profiles aphantasia’. https://doi.org/10.17605/OSF.IO/7VSX6","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/add_significance_geoms.html","id":null,"dir":"Reference","previous_headings":"","what":"Add significance label and line to a plot — add_significance_geoms","title":"Add significance label and line to a plot — add_significance_geoms","text":"Add significance label line plot","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/add_significance_geoms.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add significance label and line to a plot — add_significance_geoms","text":"","code":"add_significance_geoms(df, size_star = 2.5, lw = 0.2)"},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/add_significance_geoms.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add significance label and line to a plot — add_significance_geoms","text":"df dataframe containing one column per variable desired aesthetics (x, y, colour, etc.) following columns: x_star: x position star label y_star: y position star label stars: star label (e.g., \"\", \"\", \"\") x_line: x position start line x_line_end: x position end line y_line: y position line size_star Size star label. Default 2.5. lw Line width significance line. Default 0.2.","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/add_significance_geoms.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add significance label and line to a plot — add_significance_geoms","text":"list ggplot2 layers can added ggplot object.","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/add_significance_geoms.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add significance label and line to a plot — add_significance_geoms","text":"","code":"group_effect_verbal <-  tibble::tibble(    Variable   = factor(\"OSIVQ-Verbal\"),     x_star     = 1.5,     y_star     = 1.08,     stars      = \"**\",     x_line     = x_star - 0.5,     x_line_end = x_star + 0.5,     y_line     = 1.05   )  ggplot2::ggplot() +   ggplot2::scale_x_discrete(limits = factor(c(1, 2))) +   ggplot2::scale_y_continuous(limits = c(0, 1.1)) +   ggplot2::labs(x = NULL, y = NULL) +   ggplot2::facet_wrap(~ Variable, scales = \"free_x\") +   add_significance_geoms(group_effect_verbal, size_star = 4)"},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/aphantasiaCognitiveClustering-package.html","id":null,"dir":"Reference","previous_headings":"","what":"aphantasiaCognitiveClustering: Data Analysis for ","title":"aphantasiaCognitiveClustering: Data Analysis for ","text":"package contains code reproduce analyses reported article \"Unsupervised clustering reveals spatial verbal cognitive profiles aphantasia typical imagery\".","code":""},{"path":[]},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/aphantasiaCognitiveClustering-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"aphantasiaCognitiveClustering: Data Analysis for ","text":"Maintainer: Maël Delem mael.delem@pm.(ORCID)","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/cluster_selected_vars.html","id":null,"dir":"Reference","previous_headings":"","what":"Use Gaussian Mixture Models to cluster selected variables — cluster_selected_vars","title":"Use Gaussian Mixture Models to cluster selected variables — cluster_selected_vars","text":"Use Gaussian Mixture Models cluster selected variables","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/cluster_selected_vars.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Use Gaussian Mixture Models to cluster selected variables — cluster_selected_vars","text":"","code":"cluster_selected_vars(df, vars = NULL)"},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/cluster_selected_vars.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Use Gaussian Mixture Models to cluster selected variables — cluster_selected_vars","text":"df data frame containing variables clustered, usually study_data. vars character vector variable names clustered. NULL, default set variables used: visual_imagery sensory_imagery spatial_imagery verbal_strategies fluid_intelligence verbal_reasoning span_spatial","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/cluster_selected_vars.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Use Gaussian Mixture Models to cluster selected variables — cluster_selected_vars","text":"fitted Mclust object containing clustering results.","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/cluster_selected_vars.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Use Gaussian Mixture Models to cluster selected variables — cluster_selected_vars","text":"","code":"clustering <- cluster_selected_vars(study_data) clustering #> 'Mclust' model object: (EVE,3)  #>  #> Available components:  #>  [1] \"call\"           \"data\"           \"modelName\"      \"n\"              #>  [5] \"d\"              \"G\"              \"BIC\"            \"loglik\"         #>  [9] \"df\"             \"bic\"            \"icl\"            \"hypvol\"         #> [13] \"parameters\"     \"z\"              \"classification\" \"uncertainty\"     if (requireNamespace(\"dplyr\")) {   data.frame(cluster = clustering$classification) |>     dplyr::reframe(n = dplyr::n(), .by = cluster) } #>   cluster  n #> 1       2 34 #> 2       1 30 #> 3       3 32"},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/correlate_vars.html","id":null,"dir":"Reference","previous_headings":"","what":"Correlate the original variables with a chosen method and correction — correlate_vars","title":"Correlate the original variables with a chosen method and correction — correlate_vars","text":"Correlate original variables chosen method correction","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/correlate_vars.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Correlate the original variables with a chosen method and correction — correlate_vars","text":"","code":"correlate_vars(   df,   method = \"pearson\",   partial = TRUE,   correction = \"bonferroni\" )"},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/correlate_vars.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Correlate the original variables with a chosen method and correction — correlate_vars","text":"df data frame containing variables correlated, usually study_data. method string indicating correlation method use. Default \"pearson\". options include \"spearman\" \"kendall\". See ?correlation::correlation() details. partial Logical. Whether compute partial correlations. Default TRUE. FALSE, computes simple correlations. correction string indicating p-value correction method use. Default \"bonferroni\". options include \"holm\", \"fdr\", \"none\". See ?correlation::correlation() details.","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/correlate_vars.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Correlate the original variables with a chosen method and correction — correlate_vars","text":"data frame containing correlations variables, parameters renamed better readability.","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/correlate_vars.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Correlate the original variables with a chosen method and correction — correlate_vars","text":"","code":"simple_correlations <- correlate_vars(study_data, partial = FALSE) format(head(simple_correlations)) #>   Parameter1      Parameter2     r         95% CI t(94)         p #> 1       VVIQ   OSIVQ\\nObject  0.88 [ 0.82,  0.92] 17.55 < .001*** #> 2       VVIQ  OSIVQ\\nSpatial  0.11 [-0.09,  0.30]  1.07 > .999    #> 3       VVIQ   OSIVQ\\nVerbal -0.23 [-0.41, -0.03] -2.32 > .999    #> 4       VVIQ   Psi-Q\\nVisual  0.94 [ 0.92,  0.96] 27.69 < .001*** #> 5       VVIQ Psi-Q\\nAudition  0.80 [ 0.72,  0.86] 13.05 < .001*** #> 6       VVIQ    Psi-Q\\nSmell  0.81 [ 0.73,  0.87] 13.30 < .001***"},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/filter_study_variables.html","id":null,"dir":"Reference","previous_headings":"","what":"Filter the Variable column of a long format data frame — filter_study_variables","title":"Filter the Variable column of a long format data frame — filter_study_variables","text":"function simple helper filter Variable column study data long format. two main groups study variables, \"original\" experimental variables \"reduced\" variables created analyses. functions allows filter two selections easily, optionally filter specific set variables.","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/filter_study_variables.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Filter the Variable column of a long format data frame — filter_study_variables","text":"","code":"filter_study_variables(df, selection = \"original\", variables = NULL)"},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/filter_study_variables.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Filter the Variable column of a long format data frame — filter_study_variables","text":"df data frame long format containing Variable column filtered. example output get_longer(study_data). selection character string indicating selection variables filter . can either \"original\", \"reduced\" (reduced variables + three validation variables original set) \"reduced_strict\". want use custom set variables, set variables character vector leave selection default value. variables Optional. character vector variable names filter . NULL, function use default selection variables based selection argument. provided, override default selection.","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/filter_study_variables.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Filter the Variable column of a long format data frame — filter_study_variables","text":"data frame filtered specified variables Variable column.","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/filter_study_variables.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Filter the Variable column of a long format data frame — filter_study_variables","text":"","code":"df_merged_long <- merge_clusters(   df_raw     = study_data,   df_red     = scale_reduce_vars(study_data),   clustering = cluster_selected_vars(study_data) ) |> get_longer()  # df_merged_long contains all study and reduced variables original <- filter_study_variables(df_merged_long, selection = \"original\") reduced  <- filter_study_variables(df_merged_long, selection = \"reduced\") reduced_strict  <- filter_study_variables(  df_merged_long,  selection = \"reduced_strict\" ) custom <- filter_study_variables(   df_merged_long,   variables = c(\"VVIQ\", \"WCST\") ) levels(factor(original$Variable)) #>  [1] \"VVIQ\"                   \"OSIVQ-Object\"           \"OSIVQ-Spatial\"          #>  [4] \"OSIVQ-Verbal\"           \"Psi-Q Vision\"           \"Psi-Q Audition\"         #>  [7] \"Psi-Q Smell\"            \"Psi-Q Taste\"            \"Psi-Q Touch\"            #> [10] \"Psi-Q Sensations\"       \"Psi-Q Feelings\"         \"Raven matrices\"         #> [13] \"SRI\"                    \"Digit span\"             \"Spatial span\"           #> [16] \"Similarities test\"      \"WCST\"                   \"Reading\\ncomprehension\" levels(factor(reduced$Variable)) #>  [1] \"Visual imagery\"         \"Auditory imagery\"       \"Sensory imagery\"        #>  [4] \"Spatial imagery\"        \"Verbal strategies\"      \"Raven +\\nDigit Span\"    #>  [7] \"Verbal reasoning\"       \"Spatial span std.\"      \"WCST\"                   #> [10] \"Reading\\ncomprehension\" levels(factor(reduced_strict$Variable)) #> [1] \"Visual imagery\"      \"Sensory imagery\"     \"Spatial imagery\"     #> [4] \"Verbal strategies\"   \"Raven +\\nDigit Span\" \"Verbal reasoning\"    #> [7] \"Spatial span std.\"   levels(factor(custom$Variable)) #> [1] \"VVIQ\" \"WCST\""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/fit_stan_glm.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit a stan_glm model with predefined parameters — fit_stan_glm","title":"Fit a stan_glm model with predefined parameters — fit_stan_glm","text":"function simple wrapper around rstanarm::stan_glm() function fit Bayesian linear model using Stan. mostly designed set defaults needed package, notably number iterations seed reproducibility. provides shorter syntax fit many models, allowing reuse functions (e.g., get_full_model_table()).","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/fit_stan_glm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit a stan_glm model with predefined parameters — fit_stan_glm","text":"","code":"fit_stan_glm(   df,   formula,   chains = 4,   iter = 10000,   refresh = 0,   seed = 14051998,   prior_PD = FALSE,   ... )"},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/fit_stan_glm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit a stan_glm model with predefined parameters — fit_stan_glm","text":"df data frame. formula formula specifying model fitted, e.g. value ~ Group * Age. chains Number Markov chains run. Default 4. iter Number iterations per chain. Default 10000. refresh Refresh rate progress bar. Default 0 (progress bar). seed Seed random number generation ensure reproducibility. default, 14051998, used produce results presented scientific article associated package. prior_PD Logical. TRUE, model fitted prior predictive check. Default FALSE. ... Additional arguments passed rstanarm::stan_glm().","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/fit_stan_glm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit a stan_glm model with predefined parameters — fit_stan_glm","text":"fitted stanreg object containing results Bayesian linear model.","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/fit_stan_glm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit a stan_glm model with predefined parameters — fit_stan_glm","text":"","code":"df_vviq  <- study_data |> get_longer() |> dplyr::filter(Variable == \"VVIQ\") vviq_fit <- fit_stan_glm(df_vviq, value ~ Group * Age) summary(vviq_fit) #>  #> Model Info: #>  function:     stan_glm #>  family:       gaussian [identity] #>  formula:      value ~ Group * Age #>  algorithm:    sampling #>  sample:       20000 (posterior sample size) #>  priors:       see help('prior_summary') #>  observations: 96 #>  predictors:   4 #>  #> Estimates: #>                       mean   sd    10%   50%   90% #> (Intercept)          57.6    3.4  53.2  57.6  61.9 #> GroupAphantasic     -37.2    5.5 -44.3 -37.3 -30.2 #> Age                   0.0    0.1  -0.1   0.0   0.1 #> GroupAphantasic:Age  -0.1    0.2  -0.3  -0.1   0.1 #> sigma                 8.6    0.6   7.8   8.5   9.4 #>  #> Fit Diagnostics: #>            mean   sd   10%   50%   90% #> mean_PPD 39.5    1.2 37.9  39.5  41.0  #>  #> The mean_ppd is the sample average posterior predictive distribution of the outcome variable (for details see help('summary.stanreg')). #>  #> MCMC diagnostics #>                     mcse Rhat n_eff #> (Intercept)         0.0  1.0   9010 #> GroupAphantasic     0.1  1.0   7208 #> Age                 0.0  1.0   8917 #> GroupAphantasic:Age 0.0  1.0   6894 #> sigma               0.0  1.0  13234 #> mean_PPD            0.0  1.0  16897 #> log-posterior       0.0  1.0   6816 #>  #> For each parameter, mcse is Monte Carlo standard error, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence Rhat=1)."},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/format_association_table.html","id":null,"dir":"Reference","previous_headings":"","what":"Display the association table for a specific variable in a clean format — format_association_table","title":"Display the association table for a specific variable in a clean format — format_association_table","text":"function built specifically provide easy way display tables nested output get_association_models() clean format. really meant used outside context requires specific columns, likely work many data frames.","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/format_association_table.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Display the association table for a specific variable in a clean format — format_association_table","text":"","code":"format_association_table(df, variable)"},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/format_association_table.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Display the association table for a specific variable in a clean format — format_association_table","text":"df tibble containing association table nested table column, typically result get_association_models(). variable character string specifying variable format table. output get_association_models(), one \"Education\", \"Field\", \"Occupation\".","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/format_association_table.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Display the association table for a specific variable in a clean format — format_association_table","text":"table formatted knitr::kable(), ready displayed.","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/format_association_table.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Display the association table for a specific variable in a clean format — format_association_table","text":"","code":"df_associations <- get_association_models(study_data, group) format_association_table(df_associations, \"Education\") #> # A tibble: 6 × 3 #>   Education       Control Aphantasic #>   <fct>             <int>      <int> #> 1 Other                 5          4 #> 2 Upper secondary       1          0 #> 3 Post-secondary        9          5 #> 4 Bachelor             17         17 #> 5 Master               17         16 #> 6 Doctorate             2          3 format_association_table(df_associations, \"Field\") #> # A tibble: 11 × 3 #>    Field                                        Control Aphantasic #>    <fct>                                          <int>      <int> #>  1 Generic programmes                                 4          4 #>  2 Education                                          1          1 #>  3 Arts, humanities                                   9         12 #>  4 Social sciences, journalism, information          11          4 #>  5 Business, Administration, Law                     10          8 #>  6 Natural sciences, mathematics, statistics          6          4 #>  7 Information, communication technologies            4          4 #>  8 Engineering, manufacturing, construction           3          3 #>  9 Agriculture, forestry, fisheries, veterinary       1          1 #> 10 Health and Welfare                                 2          3 #> 11 Services                                           0          1 format_association_table(df_associations, \"Occupation\") #> # A tibble: 9 × 3 #>   Occupation                  Control Aphantasic #>   <fct>                         <int>      <int> #> 1 No answer                         1          1 #> 2 Unemployed                        1          1 #> 3 Student                          20         12 #> 4 Science and Engineering           2          4 #> 5 Health                            2          6 #> 6 Teaching                          4          3 #> 7 Business, Administration          9         10 #> 8 Information, Communications       8          6 #> 9 Social, Cultural, Legal           4          2"},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/get_association_models.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit and report Bayes Factors for associations with education, fields and occupations — get_association_models","title":"Fit and report Bayes Factors for associations with education, fields and occupations — get_association_models","text":"function computes Bayes Factors associations grouping variable (e.g., Group, Cluster) variables education, field, occupation data frame. uses BayesFactor::contingencyTableBF() function compute Bayes Factor variable returns tidy data frame results.","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/get_association_models.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit and report Bayes Factors for associations with education, fields and occupations — get_association_models","text":"","code":"get_association_models(df, groups, type = \"indepMulti\")"},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/get_association_models.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit and report Bayes Factors for associations with education, fields and occupations — get_association_models","text":"df data frame containing variables education, field, occupation, along grouping variable. groups grouping variable (e.g. Group Cluster) without quotes. type character string specifying type contingency table model use. Default \"indepMulti\", indicates independent multinomial model. See ?BayesFactor::contingencyTableBF details options.","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/get_association_models.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit and report Bayes Factors for associations with education, fields and occupations — get_association_models","text":"data frame summarising Bayes Factors associations grouping variable variables education, field, occupation, variable name Variable column, contingency table table column, log Bayes Factor log_bf10 column. variable names capitalised better readability.","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/get_association_models.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit and report Bayes Factors for associations with education, fields and occupations — get_association_models","text":"","code":"df_merged <- merge_clusters(   df_raw     = study_data,   df_red     = scale_reduce_vars(study_data),   clustering = cluster_selected_vars(study_data) ) get_association_models(df_merged, group) #> # A tibble: 3 × 4 #> # Rowwise:  Variable #>   Variable   data              table             log_bf10 #>   <chr>      <list>            <list>               <dbl> #> 1 Education  <tibble [96 × 2]> <tibble [6 × 3]>     -4.88 #> 2 Field      <tibble [96 × 2]> <tibble [11 × 3]>    -5.41 #> 3 Occupation <tibble [96 × 2]> <tibble [9 × 3]>     -4.37 get_association_models(df_merged, cluster) #> # A tibble: 3 × 4 #> # Rowwise:  Variable #>   Variable   data              table             log_bf10 #>   <chr>      <list>            <list>               <dbl> #> 1 Education  <tibble [96 × 2]> <tibble [6 × 4]>     -7.44 #> 2 Field      <tibble [96 × 2]> <tibble [11 × 4]>    -6.06 #> 3 Occupation <tibble [96 × 2]> <tibble [9 × 4]>     -3.88 get_association_models(df_merged, subcluster) #> # A tibble: 3 × 4 #> # Rowwise:  Variable #>   Variable   data              table             log_bf10 #>   <chr>      <list>            <list>               <dbl> #> 1 Education  <tibble [96 × 2]> <tibble [6 × 5]>     -9.84 #> 2 Field      <tibble [96 × 2]> <tibble [11 × 5]>    -7.7  #> 3 Occupation <tibble [96 × 2]> <tibble [9 × 5]>     -7.06 get_association_models(df_merged, group)$table #> [[1]] #> # A tibble: 6 × 3 #>   value           Control Aphantasic #>   <fct>             <int>      <int> #> 1 Other                 5          4 #> 2 Upper secondary       1          0 #> 3 Post-secondary        9          5 #> 4 Bachelor             17         17 #> 5 Master               17         16 #> 6 Doctorate             2          3 #>  #> [[2]] #> # A tibble: 11 × 3 #>    value                                        Control Aphantasic #>    <fct>                                          <int>      <int> #>  1 Generic programmes                                 4          4 #>  2 Education                                          1          1 #>  3 Arts, humanities                                   9         12 #>  4 Social sciences, journalism, information          11          4 #>  5 Business, Administration, Law                     10          8 #>  6 Natural sciences, mathematics, statistics          6          4 #>  7 Information, communication technologies            4          4 #>  8 Engineering, manufacturing, construction           3          3 #>  9 Agriculture, forestry, fisheries, veterinary       1          1 #> 10 Health and Welfare                                 2          3 #> 11 Services                                           0          1 #>  #> [[3]] #> # A tibble: 9 × 3 #>   value                       Control Aphantasic #>   <fct>                         <int>      <int> #> 1 No answer                         1          1 #> 2 Unemployed                        1          1 #> 3 Student                          20         12 #> 4 Science and Engineering           2          4 #> 5 Health                            2          6 #> 6 Teaching                          4          3 #> 7 Business, Administration          9         10 #> 8 Information, Communications       8          6 #> 9 Social, Cultural, Legal           4          2 #>"},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/get_bf_inclusion.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute Bayes Factor for Inclusion for the groups and age covariate — get_bf_inclusion","title":"Compute Bayes Factor for Inclusion for the groups and age covariate — get_bf_inclusion","text":"function computes Bayes Factor Inclusion (BFI) given grouping variable (e.g., Group, Cluster) Age covariate predicting variable (e.g., VVIQ, OSIVQ-Spatial, etc.) value column. , requires data frame value column, Variable column, grouping variable, Age covariate.","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/get_bf_inclusion.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute Bayes Factor for Inclusion for the groups and age covariate — get_bf_inclusion","text":"","code":"get_bf_inclusion(df, groups, progress = FALSE)"},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/get_bf_inclusion.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute Bayes Factor for Inclusion for the groups and age covariate — get_bf_inclusion","text":"df data frame long format containing variable analysed required columns. groups grouping variable (e.g. Group Cluster) without quotes. progress Logical. TRUE, function show progress bar computing Bayes Factor. Default FALSE.","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/get_bf_inclusion.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute Bayes Factor for Inclusion for the groups and age covariate — get_bf_inclusion","text":"data frame summarising Bayes Factor Inclusion specified grouping variable Age covariate, variable name Variable column Bayes Factor log_BF column.","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/get_bf_inclusion.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute Bayes Factor for Inclusion for the groups and age covariate — get_bf_inclusion","text":"","code":"df_vviq  <- study_data |> get_longer() |> dplyr::filter(Variable == \"VVIQ\") vviq_bfi <- get_bf_inclusion(df_vviq, Group, progress = FALSE) print(vviq_bfi) #>    Variable p_prior p_posterior log_BF #> 1     Group     0.6        1.00  84.58 #> 2       Age     0.6        0.22  -1.65 #> 3 Age:Group     0.2        0.06  -1.36"},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/get_contrast_bf.html","id":null,"dir":"Reference","previous_headings":"","what":"Get contrasts between groups in a Bayesian model — get_contrast_bf","title":"Get contrasts between groups in a Bayesian model — get_contrast_bf","text":"function wraps machinery needed compute contrasts levels grouping variable data (e.g., Group, Cluster) given variable. fits Bayesian models using fit_stan_glm() function prior posterior distributions, computes contrasts using emmeans::emmeans() pairs(), computes Bayes Factor contrasts using bayestestR::bf_parameters(). results formatted clean table.","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/get_contrast_bf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get contrasts between groups in a Bayesian model — get_contrast_bf","text":"","code":"get_contrast_bf(df, groups)"},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/get_contrast_bf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get contrasts between groups in a Bayesian model — get_contrast_bf","text":"df data frame long format containing variable analysed required columns. example output get_longer(study_data). groups grouping variable (e.g. Group Cluster) without quotes.","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/get_contrast_bf.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get contrasts between groups in a Bayesian model — get_contrast_bf","text":"data frame summarising contrasts levels grouping variable, variable name Variable column, comparison Comparison column, difference Difference ($\\Delta$) column, 95% credible interval 95% CrI column, log Bayes Factor $log(BF_{10})$ column.","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/get_contrast_bf.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get contrasts between groups in a Bayesian model — get_contrast_bf","text":"","code":"df_vviq <- study_data |> get_longer() |> dplyr::filter(Variable == \"VVIQ\") vviq_contrast <- get_contrast_bf(df_vviq, Group) print(vviq_contrast) #> # A tibble: 1 × 4 #>   Comparison           `Difference ($\\\\Delta$)` `95% CrI`      `$log(BF_{10})$` #>   <chr>                                   <dbl> <chr>                     <dbl> #> 1 Control - Aphantasic                     39.7 [36.22, 43.17]             56.6"},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/get_full_model_table.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a table summarising the models for each variable — get_full_model_table","title":"Create a table summarising the models for each variable — get_full_model_table","text":"macro-function runs various computations model variables Variable column long format data values value column grouping variable (e.g., Group, Cluster) Age variable. wraps get_mean_sd(), get_bf_inclusion(), get_contrast_bf() functions compute mean standard deviation group, Bayes Factor Inclusion grouping variable Age covariate, contrasts levels grouping variable, respectively. results formatted clean table one row per variable columns mean, standard deviation, Bayes Factor Inclusion, contrasts.","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/get_full_model_table.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a table summarising the models for each variable — get_full_model_table","text":"","code":"get_full_model_table(df_long, ...)"},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/get_full_model_table.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a table summarising the models for each variable — get_full_model_table","text":"df_long data frame long format containing variables analysed Variable column, value column, grouping variable (e.g., Group, Cluster), Age covariate. example output get_longer(study_data). ... grouping variable (e.g. Group Cluster) without quotes.","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/get_full_model_table.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a table summarising the models for each variable — get_full_model_table","text":"data frame summarising models variable.","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/get_full_model_table.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a table summarising the models for each variable — get_full_model_table","text":"","code":"df_merged <- merge_clusters(   df_raw     = study_data,   df_red     = scale_reduce_vars(study_data),   clustering = cluster_selected_vars(study_data) ) df_long_example <-  df_merged |>  get_longer() |>  dplyr::filter(Variable %in% c(\"VVIQ\"))  cluster_models <- get_full_model_table(df_long_example, Cluster) print(cluster_models) #> # A tibble: 3 × 11 #>   Variable `A (Aphant.)` `B (Mixed)`  `C (Control)` Cluster   Age #>   <fct>    <chr>         <chr>        <chr>           <dbl> <dbl> #> 1 VVIQ     18.06 (4.1)   36.5 (17.56) 62.18 (8.66)     54.9 -1.11 #> 2 VVIQ     18.06 (4.1)   36.5 (17.56) 62.18 (8.66)     54.9 -1.11 #> 3 VVIQ     18.06 (4.1)   36.5 (17.56) 62.18 (8.66)     54.9 -1.11 #> # ℹ 5 more variables: `Cluster $\\\\times$ Age` <dbl>, Comparison <chr>, #> #   `Difference ($\\\\Delta$)` <dbl>, `95% CrI` <chr>, `$log(BF_{10})$` <dbl>"},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/get_longer.html","id":null,"dir":"Reference","previous_headings":"","what":"Transform the main data frame to long format — get_longer","title":"Transform the main data frame to long format — get_longer","text":"Pivot main data frames long format. variables study (raw/original variables) created analysis (e.g., reduced variables) selected pivoted long format.","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/get_longer.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Transform the main data frame to long format — get_longer","text":"","code":"get_longer(df)"},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/get_longer.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Transform the main data frame to long format — get_longer","text":"df data frame containing main data.","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/get_longer.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Transform the main data frame to long format — get_longer","text":"data frame long format.","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/get_longer.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Transform the main data frame to long format — get_longer","text":"","code":"df_raw_long <- get_longer(study_data) head(df_raw_long[, c(\"id\", \"Variable\", \"value\")], 18) #> # A tibble: 18 × 3 #>    id    Variable                 value #>    <chr> <fct>                    <dbl> #>  1 7210  \"VVIQ\"                   65    #>  2 7210  \"OSIVQ-Object\"           45    #>  3 7210  \"OSIVQ-Spatial\"          45    #>  4 7210  \"OSIVQ-Verbal\"           54    #>  5 7210  \"Psi-Q Vision\"            8    #>  6 7210  \"Psi-Q Audition\"          7.67 #>  7 7210  \"Psi-Q Smell\"             8    #>  8 7210  \"Psi-Q Taste\"             7.33 #>  9 7210  \"Psi-Q Touch\"             8.33 #> 10 7210  \"Psi-Q Sensations\"        8.67 #> 11 7210  \"Psi-Q Feelings\"          8    #> 12 7210  \"Raven matrices\"         14    #> 13 7210  \"SRI\"                    27    #> 14 7210  \"Digit span\"              6.07 #> 15 7210  \"Spatial span\"            5.43 #> 16 7210  \"Similarities test\"      30    #> 17 7210  \"WCST\"                   78    #> 18 7210  \"Reading\\ncomprehension\" 24     df_merged <- merge_clusters(   df_raw     = study_data,   df_red     = scale_reduce_vars(study_data),   clustering = cluster_selected_vars(study_data)   ) df_full_long <- get_longer(scale_vars(df_merged)) df_full_long[, c(\"id\", \"Variable\", \"value\")] |>   head(26) |>   print(n = Inf) #> # A tibble: 26 × 3 #>    id    Variable                 value #>    <chr> <fct>                    <dbl> #>  1 7210  \"VVIQ\"                   0.766 #>  2 7210  \"OSIVQ-Object\"           0.5   #>  3 7210  \"OSIVQ-Spatial\"          0.5   #>  4 7210  \"OSIVQ-Verbal\"           0.65  #>  5 7210  \"Psi-Q Vision\"           0.778 #>  6 7210  \"Psi-Q Audition\"         0.741 #>  7 7210  \"Psi-Q Smell\"            0.778 #>  8 7210  \"Psi-Q Taste\"            0.703 #>  9 7210  \"Psi-Q Touch\"            0.814 #> 10 7210  \"Psi-Q Sensations\"       0.852 #> 11 7210  \"Psi-Q Feelings\"         0.778 #> 12 7210  \"Raven matrices\"         0.389 #> 13 7210  \"SRI\"                    0.9   #> 14 7210  \"Digit span\"             0.825 #> 15 7210  \"Spatial span\"           0.927 #> 16 7210  \"Similarities test\"      0.833 #> 17 7210  \"Visual imagery\"         0.65  #> 18 7210  \"Auditory imagery\"       0.741 #> 19 7210  \"Sensory imagery\"        0.785 #> 20 7210  \"Spatial imagery\"        0.767 #> 21 7210  \"Verbal strategies\"      0.65  #> 22 7210  \"Raven +\\nDigit Span\"    0.607 #> 23 7210  \"Verbal reasoning\"       0.833 #> 24 7210  \"Spatial span std.\"      0.927 #> 25 7210  \"WCST\"                   0.78  #> 26 7210  \"Reading\\ncomprehension\" 0.774"},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/get_mean_sd.html","id":null,"dir":"Reference","previous_headings":"","what":"Get the mean and standard deviation of a variable in a clean table — get_mean_sd","title":"Get the mean and standard deviation of a variable in a clean table — get_mean_sd","text":"point function get mean/SD clean formatted string. add much top dplyr functions, allows perform required computations single line code use inside functions (e.g., get_full_model_table()).","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/get_mean_sd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get the mean and standard deviation of a variable in a clean table — get_mean_sd","text":"","code":"get_mean_sd(df, groups)"},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/get_mean_sd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get the mean and standard deviation of a variable in a clean table — get_mean_sd","text":"df data frame containing variable summarised long format, name column associated values value column. example output get_longer(study_data). groups grouping variable (e.g. Group Cluster) without quotes.","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/get_mean_sd.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get the mean and standard deviation of a variable in a clean table — get_mean_sd","text":"data frame summarising mean standard deviation variable group wide format one column per group.","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/get_mean_sd.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get the mean and standard deviation of a variable in a clean table — get_mean_sd","text":"","code":"df_vviq  <- study_data |> get_longer() |> dplyr::filter(Variable == \"VVIQ\") vviq_mean_sd <- get_mean_sd(df_vviq, Group) print(vviq_mean_sd) #> # A tibble: 1 × 2 #>   Control       Aphantasic   #>   <chr>         <chr>        #> 1 58.08 (10.81) 18.33 (4.24)"},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/merge_clusters.html","id":null,"dir":"Reference","previous_headings":"","what":"Add the clustering and reduced variables to the main data frame — merge_clusters","title":"Add the clustering and reduced variables to the main data frame — merge_clusters","text":"Add clustering reduced variables main data frame","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/merge_clusters.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add the clustering and reduced variables to the main data frame — merge_clusters","text":"","code":"merge_clusters(df_raw, df_red, clustering, names = c(\"B\", \"C\", \"A\"))"},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/merge_clusters.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add the clustering and reduced variables to the main data frame — merge_clusters","text":"df_raw data frame containing raw data, usually study_data. df_red data frame containing reduced variables, usually scale_reduce_vars(). clustering fitted Mclust object containing clustering results, usually cluster_selected_vars(). names character vector cluster names. Default c(\"B\", \"C\", \"\"). default based last iteration clustering date (article based ).","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/merge_clusters.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add the clustering and reduced variables to the main data frame — merge_clusters","text":"data frame columns raw data, reduced variables, cluster column cluster names subcluster column cluster group names.","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/merge_clusters.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add the clustering and reduced variables to the main data frame — merge_clusters","text":"","code":"df_merged <- merge_clusters(   df_raw     = study_data,   df_red     = scale_reduce_vars(study_data),   clustering = cluster_selected_vars(study_data) ) head(df_merged) #> # A tibble: 6 × 37 #>   id    group      cluster     subcluster   age sex   education field field_code #>   <chr> <fct>      <fct>       <fct>      <dbl> <fct> <fct>     <fct> <fct>      #> 1 7210  Control    C (Control) C (Contro…    25 m     Master    Soci… 3          #> 2 7213  Control    C (Control) C (Contro…    22 f     Master    Soci… 3          #> 3 7238  Control    B (Mixed)   B-Control     52 f     Bachelor  Natu… 5          #> 4 7242  Control    C (Control) C (Contro…    48 f     Post-sec… Busi… 4          #> 5 7254  Aphantasic A (Aphant.) A (Aphant…    37 f     Doctorate Heal… 9          #> 6 7257  Control    B (Mixed)   B-Control     36 m     Bachelor  Natu… 5          #> # ℹ 28 more variables: occupation <fct>, occupation_code <fct>, vviq <dbl>, #> #   osivq_o <dbl>, osivq_s <dbl>, osivq_v <dbl>, psiq_vis <dbl>, #> #   psiq_aud <dbl>, psiq_od <dbl>, psiq_gout <dbl>, psiq_tou <dbl>, #> #   psiq_sens <dbl>, psiq_feel <dbl>, score_raven <dbl>, score_sri <dbl>, #> #   span_spatial <dbl>, span_digit <dbl>, wcst_accuracy <dbl>, #> #   score_similarities <dbl>, score_comprehension <dbl>, visual_imagery <dbl>, #> #   auditory_imagery <dbl>, sensory_imagery <dbl>, spatial_imagery <dbl>, … colnames(df_merged) #>  [1] \"id\"                  \"group\"               \"cluster\"             #>  [4] \"subcluster\"          \"age\"                 \"sex\"                 #>  [7] \"education\"           \"field\"               \"field_code\"          #> [10] \"occupation\"          \"occupation_code\"     \"vviq\"                #> [13] \"osivq_o\"             \"osivq_s\"             \"osivq_v\"             #> [16] \"psiq_vis\"            \"psiq_aud\"            \"psiq_od\"             #> [19] \"psiq_gout\"           \"psiq_tou\"            \"psiq_sens\"           #> [22] \"psiq_feel\"           \"score_raven\"         \"score_sri\"           #> [25] \"span_spatial\"        \"span_digit\"          \"wcst_accuracy\"       #> [28] \"score_similarities\"  \"score_comprehension\" \"visual_imagery\"      #> [31] \"auditory_imagery\"    \"sensory_imagery\"     \"spatial_imagery\"     #> [34] \"verbal_strategies\"   \"fluid_intelligence\"  \"verbal_reasoning\"    #> [37] \"spatial_span\"        df_merged |>   dplyr::reframe(     .by = cluster,     n = dplyr::n(),     vviq    = mean(vviq),     object  = mean(osivq_o),     spatial = mean(osivq_s),     verbal  = mean(osivq_v)    ) |>    dplyr::arrange(cluster) |>    print() #> # A tibble: 3 × 6 #>   cluster         n  vviq object spatial verbal #>   <fct>       <int> <dbl>  <dbl>   <dbl>  <dbl> #> 1 A (Aphant.)    32  18.1   23.9    37.6   52.8 #> 2 B (Mixed)      30  36.5   39.1    47.5   41.4 #> 3 C (Control)    34  62.2   56.7    40.0   44"},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/models_list.html","id":null,"dir":"Reference","previous_headings":"","what":"Models for all the variables predicted by Groups, Clusters and Sub-clusters — models_list","title":"Models for all the variables predicted by Groups, Clusters and Sub-clusters — models_list","text":"list contains three data frames summarising following: group_models: Models unstandaridsed variables predicted Groups (aphantasia/control) cluster_models: Models standardised variables predicted Clusters (/B/C) subcluster_models: Models standardised variables predicted Sub-clusters (/B-Aphant/B-Control/C)","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/models_list.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Models for all the variables predicted by Groups, Clusters and Sub-clusters — models_list","text":"","code":"models_list"},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/models_list.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Models for all the variables predicted by Groups, Clusters and Sub-clusters — models_list","text":"object class list length 3.","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/models_list.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Models for all the variables predicted by Groups, Clusters and Sub-clusters — models_list","text":"tables obtained get_full_model_table() function included package. saved list exists avoid re-running slow computations (two Bayesian models variable compute contrasts).","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/plot_clusters_bic.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot the comparison of Gaussian Mixture Models (GMM) BIC scores — plot_clusters_bic","title":"Plot the comparison of Gaussian Mixture Models (GMM) BIC scores — plot_clusters_bic","text":"function wrapper around factoextra::fviz_mclust_bic() function plot Bayesian Information Criterion (BIC) scores Gaussian Mixture Models (GMM) fitted dataset. mainly designed facilitate setting various default options fit graphical style project.","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/plot_clusters_bic.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot the comparison of Gaussian Mixture Models (GMM) BIC scores — plot_clusters_bic","text":"","code":"plot_clusters_bic(   mclust_object,   txt_big = 7,   txt_mid = 6,   txt_smol = 5,   size = 0.2 )"},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/plot_clusters_bic.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot the comparison of Gaussian Mixture Models (GMM) BIC scores — plot_clusters_bic","text":"mclust_object fitted Mclust object containing clustering results, usually cluster_selected_vars(). txt_big Size plot, x-axis legend titles. Default 7. txt_mid Size legend text. Default 6. txt_smol Size axis text. Default 5. size Size points plot. Default 0.2.","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/plot_clusters_bic.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot the comparison of Gaussian Mixture Models (GMM) BIC scores — plot_clusters_bic","text":"ggplot2 object containing BIC plot.","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/plot_clusters_bic.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot the comparison of Gaussian Mixture Models (GMM) BIC scores — plot_clusters_bic","text":"","code":"study_data |> cluster_selected_vars() |> plot_clusters_bic()"},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/plot_score_cor_graph.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot a correlation graph — plot_score_cor_graph","title":"Plot a correlation graph — plot_score_cor_graph","text":"function creates graph visualisation set correlations computed using correlation::correlation(), result correlate_vars(). designed highlight nodes specific variables study (based partial correlations), run set correlations.","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/plot_score_cor_graph.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot a correlation graph — plot_score_cor_graph","text":"","code":"plot_score_cor_graph(   correlations,   shape = 21,   stroke = 0.1,   node_size = 14,   node_text_size = 5,   label_text_size = 2 )"},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/plot_score_cor_graph.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot a correlation graph — plot_score_cor_graph","text":"correlations data frame containing correlations, typically output correlate_vars(). shape Shape nodes graph. Default 21 (circle). stroke Stroke width nodes. Default 0.1. node_size Size nodes graph. Default 14. node_text_size Size text labels nodes. Default 5. label_text_size Size text labels edges. Default 2.","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/plot_score_cor_graph.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot a correlation graph — plot_score_cor_graph","text":"ggplot2 object representing correlation graph.","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/plot_score_cor_graph.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot a correlation graph — plot_score_cor_graph","text":"","code":"study_data |> correlate_vars(partial = FALSE) |> plot_score_cor_graph()"},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/plot_score_cor_joint.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a joint matrix + graph correlation figure — plot_score_cor_joint","title":"Create a joint matrix + graph correlation figure — plot_score_cor_joint","text":"function combines correlation matrix graph visualisation correlations single plot using patchwork package. two underlying functions (plot_score_cor_matrix() plot_score_cor_graph()) fairly generic, function tailored study data article. recommended use together package functions (see examples).","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/plot_score_cor_joint.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a joint matrix + graph correlation figure — plot_score_cor_joint","text":"","code":"plot_score_cor_joint(   correlations,   size_axis = 6,   matrix_text = 5,   shape = 21,   stroke = 0.1,   node_size = 14,   node_text_size = 5,   label_text_size = 2 )"},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/plot_score_cor_joint.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a joint matrix + graph correlation figure — plot_score_cor_joint","text":"correlations data frame containing correlations, typically output correlate_vars(). size_axis Size axis text points. Default 6. matrix_text Size text correlation matrix. Default 5. shape Shape nodes graph. Default 21 (circle). stroke Stroke width nodes. Default 0.1. node_size Size nodes graph. Default 14. node_text_size Size text labels nodes. Default 5. label_text_size Size text labels edges. Default 2.","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/plot_score_cor_joint.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a joint matrix + graph correlation figure — plot_score_cor_joint","text":"ggplot2 object representing joint plot correlation matrix graph.","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/plot_score_cor_joint.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a joint matrix + graph correlation figure — plot_score_cor_joint","text":"","code":"study_data |> correlate_vars(partial = FALSE) |> plot_score_cor_joint()"},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/plot_score_cor_matrix.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot a correlation matrix — plot_score_cor_matrix","title":"Plot a correlation matrix — plot_score_cor_matrix","text":"function wrapper around correlation::visualisation_recipe() function plot correlation matrix correlation package custom pre-defined options. designed fit graphical style project, specific project can used correlation matrix data.","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/plot_score_cor_matrix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot a correlation matrix — plot_score_cor_matrix","text":"","code":"plot_score_cor_matrix(correlations, size_axis = 6, matrix_text = 5)"},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/plot_score_cor_matrix.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot a correlation matrix — plot_score_cor_matrix","text":"correlations object produced correlation::correlation(), output correlate_vars(). size_axis Size axis text points. Default 6. matrix_text Size text correlation matrix. Default 5.","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/plot_score_cor_matrix.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot a correlation matrix — plot_score_cor_matrix","text":"ggplot2 object containing correlation matrix plot.","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/plot_score_cor_matrix.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot a correlation matrix — plot_score_cor_matrix","text":"","code":"study_data |> correlate_vars(partial = FALSE) |> plot_score_cor_matrix()"},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/plot_score_radars.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot scaled score variables as radar charts — plot_score_radars","title":"Plot scaled score variables as radar charts — plot_score_radars","text":"function plots scaled score variables radar charts using superb package. can plot radars combination Group, Cluster, Subcluster grouping variables selections original reduced study variables, typically obtained get_longer() filter_study_variables() (see examples). function allows customisation radar charts various options. Note default sizes pretty small, designed render best small dimension PDF vector figures journals.","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/plot_score_radars.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot scaled score variables as radar charts — plot_score_radars","text":"","code":"plot_score_radars(   df,   groups,   txt_big = 7,   txt_smol = 5,   dot_size = 0.8,   lw_line = 0.2,   lw_error = 0.2,   y_off = 40,   r_off = 0,   l_off = 0,   v_off = 0,   key = 3,   ... )"},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/plot_score_radars.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot scaled score variables as radar charts — plot_score_radars","text":"df data frame containing variables plotted long format, variable names Variable column associated values value column. example output get_longer(study_data). groups grouping variable among Group, Cluster, Subcluster. Can quoted unquoted. function plot radars level variable. txt_big Size text x-axis labels. Default 7. txt_smol Size text y-axis labels. Default 5. dot_size Size dots radar charts. Default 0.8. lw_line, lw_error Line width main plot lines error bars, respectively. Default 0.2 . y_off Offset y-axis text centre . Default 40. r_off, l_off, v_off Right, left vertical offset plot margins. Default 0 three. key Size legend key mm. Default 3. ... Additional arguments passed superb function.","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/plot_score_radars.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot scaled score variables as radar charts — plot_score_radars","text":"ggplot object containing radar chart.","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/plot_score_radars.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot scaled score variables as radar charts — plot_score_radars","text":"","code":"df_merged_long <- merge_clusters(   df_raw     = study_data,   df_red     = scale_reduce_vars(study_data),   clustering = cluster_selected_vars(study_data)   ) |>   scale_vars() |>   get_longer()  if (require(\"superb\", quietly = TRUE)) { # Groups on the original variables p1 <-   df_merged_long |>   filter_study_variables(\"original\") |>   plot_score_radars(Group, r_off = 6, l_off = 6)  # Clusters on the reduced + validation variables p2 <-   df_merged_long |>   filter_study_variables(\"reduced\") |>   plot_score_radars(Cluster, r_off = 6, l_off = 6)  # Subclusters on the reduced variables p3 <-   df_merged_long |>   filter_study_variables(\"reduced_strict\") |>   plot_score_radars(Subcluster, r_off = 6, l_off = 6)  # Clusters on all the variables p4 <- df_merged_long |> plot_score_radars(Cluster, r_off = 6, l_off = 6)  if (require(\"patchwork\", quietly = TRUE)) {  print(p1 + p2)  print(p3 + p4) } else print(p1) }"},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/plot_score_violins.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot the study variables' distributions as half-violins with point averages and error bars. — plot_score_violins","title":"Plot the study variables' distributions as half-violins with point averages and error bars. — plot_score_violins","text":"function contains machinery produce main figure group comparisons article. default, adds significance labels pre-defined locations group effects (based analysis results). sets various defaults palette groups various geom options. Note default sizes pretty small, designed render best small dimension PDF vector figures journals. function flexible (mostly designed single plot initially). , best suited plot original variable significance labels, selection scaled variables without significance labels (see examples).","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/plot_score_violins.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot the study variables' distributions as half-violins with point averages and error bars. — plot_score_violins","text":"","code":"plot_score_violins(   df,   add_signif = TRUE,   palette = c(\"#56B4E9\", \"#009E73\"),   txt_big = 7,   txt_mid = 6,   txt_smol = 5,   dot_big = 0.35,   lw_big = 0.1,   lw_smol = 0.1,   jit_w = 0.3,   jit_h = 0,   alpha = 0.3,   nrow = 2 )"},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/plot_score_violins.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot the study variables' distributions as half-violins with point averages and error bars. — plot_score_violins","text":"df data frame long format containing variables plotted. add_signif logical indicating whether add significance labels lines plot pre-defined locations. Default TRUE. set FALSE, plot include significance labels lines. palette character vector colours use groups. Default c(\"#56B4E9\", \"#009E73\"), colours used article. txt_big size text main plot axis legend. Default 7. txt_mid size text facet labels. Default 6. txt_smol size text y axis labels. Default 5. dot_big size points plot. Default 0.35. lw_big line width main plot lines. Default 0.1. lw_smol line width minor plot lines. Default 0.1. jit_w width jitter points plot. Default 0.3. jit_h height jitter points plot. Default 0. alpha alpha transparency points half-violins. nrow number rows facet grid. Default 2.","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/plot_score_violins.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot the study variables' distributions as half-violins with point averages and error bars. — plot_score_violins","text":"ggplot2 object.","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/plot_score_violins.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot the study variables' distributions as half-violins with point averages and error bars. — plot_score_violins","text":"","code":"# The figure from the article study_data |>   scale_vars() |>   get_longer() |>   filter_study_variables(\"original\") |>   plot_score_violins(add_signif = TRUE, nrow = 2)   # Alternative use with reduced scaled variables only merge_clusters(   df_raw     = study_data,   df_red     = scale_reduce_vars(study_data),   clustering = cluster_selected_vars(study_data)   ) |>   scale_vars() |>   get_longer() |>   filter_study_variables(\"reduced_strict\") |>   plot_score_violins(add_signif = FALSE, nrow = 2)"},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/save_ggplot.html","id":null,"dir":"Reference","previous_headings":"","what":"Custom ggsave wrapper set with Nature's formatting guidelines (width-locked) — save_ggplot","title":"Custom ggsave wrapper set with Nature's formatting guidelines (width-locked) — save_ggplot","text":"See: https://www.nature.com/documents/NRJs-guide--preparing-final-artwork.pdf pretty strict. one column figure 88 mm wide two column figure 180 mm wide. Depending length figure caption, different maximum heights (see PDF). figures types must vector format prevent quality loss zooming . Ever since found guidelines, use figures, even Nature... looks nice like .","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/save_ggplot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Custom ggsave wrapper set with Nature's formatting guidelines (width-locked) — save_ggplot","text":"","code":"save_ggplot(   plot,   path,   ncol = 1,   height = 90,   show = FALSE,   verbose = TRUE,   ... )"},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/save_ggplot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Custom ggsave wrapper set with Nature's formatting guidelines (width-locked) — save_ggplot","text":"plot ggplot object save. path character string path save plot. ncol number columns plot. Either 1 (default) 2. height height plot mm. Default 90 mm. show Logical. Whether return plot visibly . Default FALSE, plot returned invisibly. verbose Logical. Whether print message console saving done. Default TRUE. ... Additional arguments passed ggsave().","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/save_ggplot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Custom ggsave wrapper set with Nature's formatting guidelines (width-locked) — save_ggplot","text":"Nothing. function saves ggplot specified path.","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/scale_reduce_vars.html","id":null,"dir":"Reference","previous_headings":"","what":"Reduce the number of variables to prepare for clustering — scale_reduce_vars","title":"Reduce the number of variables to prepare for clustering — scale_reduce_vars","text":"Reduce number variables prepare clustering","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/scale_reduce_vars.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reduce the number of variables to prepare for clustering — scale_reduce_vars","text":"","code":"scale_reduce_vars(df, min = 0, max = 1)"},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/scale_reduce_vars.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reduce the number of variables to prepare for clustering — scale_reduce_vars","text":"df data frame containing variables reduced. contain following columns: vviq: VVIQ scores osivq_o: OSIVQ Object scores osivq_s: OSIVQ Spatial scores osivq_v: OSIVQ Verbal scores psiq_vis: Psi-Q Visual scores psiq_aud: Psi-Q Auditory scores psiq_od: Psi-Q Olfactory scores psiq_gout: Psi-Q Gustatory scores psiq_tou: Psi-Q Tactile scores psiq_sens: Psi-Q Sensory scores psiq_feel: Psi-Q Feelings scores score_raven: Raven Matrices scores score_sri: SRI scores span_spatial: Spatial Span scores span_digit: Digit Span scores wcst_accuracy: WCST accuracy scores score_similarities: Similarities scores score_comprehension: Comprehension scores min Numeric. minimum value scaled range. Default 0. max Numeric. maximum value scaled range. Default 1.","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/scale_reduce_vars.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reduce the number of variables to prepare for clustering — scale_reduce_vars","text":"data frame reduced variables, including: visual_imagery: Merged VVIQ, OSIVQ Object, Psi-Q Visual scores auditory_imagery: Psi-Q Auditory scores sensory_imagery: Merged Psi-Q scores modalities spatial_imagery: Merged SRI OSIVQ Spatial scores verbal_strategies: OSIVQ Verbal scores fluid_intelligence: Merged Raven Digit Span scores verbal_reasoning: Similarities scores span_spatial: Spatial Span scores","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/scale_reduce_vars.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reduce the number of variables to prepare for clustering — scale_reduce_vars","text":"","code":"df_reduced <- scale_reduce_vars(study_data) head(df_reduced) #> # A tibble: 6 × 8 #>   visual_imagery auditory_imagery sensory_imagery spatial_imagery #>            <dbl>            <dbl>           <dbl>           <dbl> #> 1          0.65             0.741           0.785           0.767 #> 2          0.617            0.889           0.771           0.745 #> 3          0.471            0.703           0.637           0.661 #> 4          0.713            0.814           0.778           0.444 #> 5          0.125            0               0               0.439 #> 6          0.703            0.778           0.578           0.761 #> # ℹ 4 more variables: verbal_strategies <dbl>, fluid_intelligence <dbl>, #> #   verbal_reasoning <dbl>, span_spatial <dbl> colnames(df_reduced) #> [1] \"visual_imagery\"     \"auditory_imagery\"   \"sensory_imagery\"    #> [4] \"spatial_imagery\"    \"verbal_strategies\"  \"fluid_intelligence\" #> [7] \"verbal_reasoning\"   \"span_spatial\""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/scale_vars.html","id":null,"dir":"Reference","previous_headings":"","what":"Scale original quantitative variables to a defined range — scale_vars","title":"Scale original quantitative variables to a defined range — scale_vars","text":"function require variables present dataframe, dataframe can used. function simply modifies columns interest ","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/scale_vars.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Scale original quantitative variables to a defined range — scale_vars","text":"","code":"scale_vars(df, min = 0, max = 1)"},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/scale_vars.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Scale original quantitative variables to a defined range — scale_vars","text":"df data frame containing variables scaled, usually study_data. min Numeric. minimum value scaled range. Default 0. max Numeric. maximum value scaled range. Default 1.","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/scale_vars.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Scale original quantitative variables to a defined range — scale_vars","text":"data frame original variables scaled specified range.","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/scale_vars.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Scale original quantitative variables to a defined range — scale_vars","text":"","code":"df_scaled <- scale_vars(study_data, min = 0, max = 1) head(df_scaled) #> # A tibble: 6 × 27 #>   id      age sex   group  education field field_code occupation occupation_code #>   <chr> <dbl> <fct> <fct>  <fct>     <fct> <fct>      <fct>      <fct>           #> 1 7210  0.13  m     Contr… Master    Soci… 3          Health     5               #> 2 7213  0.065 f     Contr… Master    Soci… 3          Student    3               #> 3 7238  0.717 f     Contr… Bachelor  Natu… 5          Informati… 8               #> 4 7242  0.63  f     Contr… Post-sec… Busi… 4          Business,… 7               #> 5 7254  0.391 f     Aphan… Doctorate Heal… 9          Health     5               #> 6 7257  0.37  m     Contr… Bachelor  Natu… 5          Business,… 7               #> # ℹ 18 more variables: vviq <dbl>, osivq_o <dbl>, osivq_s <dbl>, osivq_v <dbl>, #> #   psiq_vis <dbl>, psiq_aud <dbl>, psiq_od <dbl>, psiq_gout <dbl>, #> #   psiq_tou <dbl>, psiq_sens <dbl>, psiq_feel <dbl>, score_raven <dbl>, #> #   score_sri <dbl>, span_spatial <dbl>, span_digit <dbl>, wcst_accuracy <dbl>, #> #   score_similarities <dbl>, score_comprehension <dbl> colnames(df_scaled) #>  [1] \"id\"                  \"age\"                 \"sex\"                 #>  [4] \"group\"               \"education\"           \"field\"               #>  [7] \"field_code\"          \"occupation\"          \"occupation_code\"     #> [10] \"vviq\"                \"osivq_o\"             \"osivq_s\"             #> [13] \"osivq_v\"             \"psiq_vis\"            \"psiq_aud\"            #> [16] \"psiq_od\"             \"psiq_gout\"           \"psiq_tou\"            #> [19] \"psiq_sens\"           \"psiq_feel\"           \"score_raven\"         #> [22] \"score_sri\"           \"span_spatial\"        \"span_digit\"          #> [25] \"wcst_accuracy\"       \"score_similarities\"  \"score_comprehension\""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/study_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Study data retrieved from the OSF project — study_data","title":"Study data retrieved from the OSF project — study_data","text":"dataset contains tidied data retrieved OSF project. data preprocessed raw data files extracted JATOS server beforehand. raw data bundled package keep lightweight, functions extract available internal functions code example included data-raw/raw_data_extraction.R.","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/study_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Study data retrieved from the OSF project — study_data","text":"","code":"study_data"},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/study_data.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Study data retrieved from the OSF project — study_data","text":"object class tbl_df (inherits tbl, data.frame) 96 rows 27 columns.","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/study_data.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Study data retrieved from the OSF project — study_data","text":"Data collected online experiment. See https://osf.io/7vsx6/files/osfstorage.","code":""},{"path":"https://m-delem.github.io/aphantasiaCognitiveClustering/reference/study_data.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Study data retrieved from the OSF project — study_data","text":"dataset contains following columns: id: Participant ID age: Participant age sex: Participant sex group: Participant VVIQ group (Aphantasic/Control) education: Participant education level (ISCED classification) field: Participant field study/work (ISCED-F classification) field_code: Participant field study/work code (ISCED-F classification) occupation: Participant occupation field (ISCO classification) occupation_code: Participant occupation field code (ISCO classification) vviq: Vividness Visual Imagery Questionnaire score osivq_o: Object imagery score OSIVQ questionnaire osivq_s: Spatial imagery score OSIVQ questionnaire osivq_v: Verbal score OSIVQ questionnaire psiq_vis: Psi-Q Visual imagery score psiq_aud: Psi-Q Auditory imagery score psiq_od: Psi-Q Olfactory imagery score psiq_gout: Psi-Q Gustatory imagery score psiq_tou: Psi-Q Tactile imagery score psiq_sens: Psi-Q Sensory imagery score psiq_feel: Psi-Q Feelings imagery score score_raven: Raven Matrices score score_sri: SRI score span_digit: Digit Span score span_spatial: Spatial Span score score_similarities: Similarities test score wcst_accuracy: Wisconsin Card Sorting Test accuracy score score_comprehension: Reading comprehension score","code":""}]
